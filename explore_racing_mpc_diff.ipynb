{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Jul 30 03:26:23 PM: Encountered unexpected exception importing solver GLOP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.5.2237). Expected < 9.5.0.Please open a feature request on cvxpy to enable support for this version.')\n",
      "(CVXPY) Jul 30 03:26:23 PM: Encountered unexpected exception importing solver PDLP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.5.2237). Expected < 9.5.0.Please open a feature request on cvxpy to enable support for this version.')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpc.track.src import simple_track_generator, track_functions\n",
    "from mpc import mpc\n",
    "from mpc.mpc import GradMethods, QuadCost, LinDx\n",
    "\n",
    "from torch.func import jacfwd, vmap\n",
    "\n",
    "import utils\n",
    "\n",
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "\n",
    "import torch.autograd.functional as F\n",
    "\n",
    "from mpc import casadi_control\n",
    "\n",
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from casadi import *\n",
    "\n",
    "class CasadiControl():\n",
    "    def __init__(self, track_coordinates, params):\n",
    "        super().__init__()\n",
    "\n",
    "        params = params.numpy()\n",
    "        \n",
    "        # states: sigma, d, phi, v (4) + sigma_0, sigma_diff (2) + d_pen (1) + v_ub (1) + ac_ub (1)\n",
    "        self.n_state = 4+2+1+1+1\n",
    "        print(self.n_state)          # here add amount of states plus amount of exact penalty terms\n",
    "        # control: a, delta\n",
    "        self.n_ctrl = 2\n",
    "\n",
    "        self.track_coordinates = track_coordinates\n",
    "\n",
    "        # everything to calculate curvature\n",
    "        self.track_sigma = self.track_coordinates[2,:]\n",
    "        self.track_curv = self.track_coordinates[4,:]\n",
    "\n",
    "        self.track_curv_shift = torch.empty(self.track_curv.size())\n",
    "        self.track_curv_shift[1:] = self.track_curv[0:-1]\n",
    "        self.track_curv_shift[0] = self.track_curv[-1]\n",
    "        self.track_curv_diff = self.track_curv - self.track_curv_shift\n",
    "\n",
    "        self.mask = torch.where(torch.absolute(self.track_curv_diff) < 0.1, False, True)\n",
    "        self.sigma_f = self.track_sigma[self.mask]\n",
    "        self.curv_f = self.track_curv_diff[self.mask]\n",
    "\n",
    "        self.params = params\n",
    "\n",
    "        self.l_r = params[0]\n",
    "        self.l_f = params[1]\n",
    "        \n",
    "        self.track_width = params[2]\n",
    "        \n",
    "        self.delta_threshold_rad = np.pi\n",
    "        self.dt = params[3]\n",
    "\n",
    "        self.smooth_curve = params[4]\n",
    "        \n",
    "        self.v_max = params[5]\n",
    "        \n",
    "        self.delta_max = params[6]\n",
    "        \n",
    "        self.a_max = params[7]\n",
    "        \n",
    "        self.mpc_T = int(params[8])\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return (tanh(x/2)+1.)/2\n",
    "\n",
    "    def curv_casadi(self, sigma):\n",
    "        \n",
    "        num_sf = self.sigma_f.size()\n",
    "        num_s = sigma.size()\n",
    "\n",
    "        sigma_f_mat = self.sigma_f.repeat(num_s[1],1)\n",
    "   \n",
    "        sigma_f_mat_np = sigma_f_mat.numpy()\n",
    "        sigma_f_np = self.sigma_f.numpy()\n",
    "        curv_f_np = self.curv_f.numpy()\n",
    "\n",
    "        sigma_shifted = reshape(sigma,num_s[1],1)- sigma_f_mat_np\n",
    "        curv_unscaled = self.sigmoid(self.smooth_curve*sigma_shifted)\n",
    "        curv = reshape((curv_unscaled@(curv_f_np.reshape(-1,1))),1,num_s[1])\n",
    "\n",
    "        return curv\n",
    "    \n",
    "    \n",
    "    def mpc_casadi(self,q,p,x0_np,dx,du):\n",
    "        mpc_T = self.mpc_T\n",
    "\n",
    "        x_sym = SX.sym('x_sym',dx,mpc_T+1)\n",
    "        u_sym = SX.sym('u_sym',du,mpc_T)\n",
    "\n",
    "        beta = np.arctan(l_r/(l_r+l_f)*np.tan(u_sym[1,0:mpc_T]))\n",
    "\n",
    "        dyn1 = horzcat(\n",
    "            (x_sym[0,0] - x0_np[0]), \n",
    "            (x_sym[0,1:mpc_T+1] - x_sym[0,0:mpc_T] - dt*(x_sym[3,0:mpc_T]*(np.cos(x_sym[2,0:mpc_T]+beta)/(1.-self.curv_casadi(x_sym[0,0:mpc_T])*x_sym[1,0:mpc_T])))))\n",
    "\n",
    "        dyn2 = horzcat(\n",
    "            (x_sym[1,0] - x0_np[1]), \n",
    "            (x_sym[1,1:mpc_T+1] - x_sym[1,0:mpc_T] - dt*(x_sym[3,0:mpc_T]*np.sin(x_sym[2,0:mpc_T]+beta))))\n",
    "\n",
    "        dyn3 = horzcat(\n",
    "            (x_sym[2,0] - x0_np[2]), \n",
    "            (x_sym[2,1:mpc_T+1] - x_sym[2,0:mpc_T] - dt*(x_sym[3,0:mpc_T]*(1/l_f)*np.sin(beta)-self.curv_casadi(x_sym[0,0:mpc_T])*x_sym[3,0:mpc_T]*(np.cos(x_sym[2,0:mpc_T]+beta)/(1-self.curv_casadi(x_sym[0,0:mpc_T])*x_sym[1,0:mpc_T])))))\n",
    "\n",
    "        dyn4 = horzcat(\n",
    "            (x_sym[3,0] - x0_np[3]), \n",
    "            (x_sym[3,1:mpc_T+1] - x_sym[3,0:mpc_T] - dt*(u_sym[0,0:mpc_T])))\n",
    "\n",
    "        feat = vertcat(x_sym[0,0:mpc_T]-x0_np[0],x_sym[1:,0:mpc_T],u_sym[:,0:mpc_T])\n",
    "\n",
    "        q_sym = SX.sym('q_sym',dx+du,mpc_T)\n",
    "        p_sym = SX.sym('q_sym',dx+du,mpc_T)\n",
    "        Q_sym = diag(q_sym)\n",
    "\n",
    "        l = sum2(sum1(0.5*q_sym*feat*feat + p_sym*feat))\n",
    "        dl = substitute(substitute(l,q_sym,q),p_sym,p)\n",
    "\n",
    "        const = vertcat(\n",
    "                transpose(dyn1),\n",
    "                transpose(dyn2),\n",
    "                transpose(dyn3),\n",
    "                transpose(dyn4),\n",
    "                transpose(u_sym[0,0:mpc_T]),\n",
    "                transpose(u_sym[1,0:mpc_T]),\n",
    "                transpose(x_sym[1,0:mpc_T+1]),\n",
    "                transpose(x_sym[3,0:mpc_T+1]))\n",
    "\n",
    "        lbg = np.r_[np.zeros(mpc_T+1),\n",
    "                    np.zeros(mpc_T+1),\n",
    "                    np.zeros(mpc_T+1),\n",
    "                    np.zeros(mpc_T+1),\n",
    "                    -self.a_max*np.ones(mpc_T),\n",
    "                    -self.delta_max*np.ones(mpc_T),\n",
    "                    -0.35*self.track_width*np.ones(mpc_T+1),\n",
    "                    -0.1*np.ones(mpc_T+1)]\n",
    "\n",
    "        ubg = np.r_[np.zeros(mpc_T+1),\n",
    "                    np.zeros(mpc_T+1),\n",
    "                    np.zeros(mpc_T+1),\n",
    "                    np.zeros(mpc_T+1),\n",
    "                    self.a_max*np.ones(mpc_T),\n",
    "                    self.delta_max*np.ones(mpc_T),\n",
    "                    0.35*self.track_width*np.ones(mpc_T+1),\n",
    "                    self.v_max*np.ones(mpc_T+1)]\n",
    "\n",
    "\n",
    "        lbx = -np.inf * np.ones(dx*(mpc_T+1)+du*mpc_T)\n",
    "        ubx = np.inf * np.ones(dx*(mpc_T+1)+du*mpc_T)\n",
    "\n",
    "        x = vertcat(reshape(x_sym[:,0:mpc_T+1],(dx*(mpc_T+1),1)),\n",
    "                    reshape(u_sym[:,0:mpc_T],(du*mpc_T,1)))\n",
    "\n",
    "        options = {\n",
    "                    'verbose': False,\n",
    "                    'ipopt.print_level': 0,\n",
    "                    'print_time': 0,\n",
    "                    'ipopt.tol': 1e-4,\n",
    "                    'ipopt.max_iter': 4000,\n",
    "                    'ipopt.hessian_approximation': 'limited-memory'\n",
    "                }\n",
    "\n",
    "        nlp = {'x':x,'f':dl, 'g':const}\n",
    "        solver = nlpsol('solver','ipopt', nlp, options)\n",
    "\n",
    "        solver_input = {}\n",
    "        solver_input['lbx'] = lbx\n",
    "        solver_input['ubx'] = ubx\n",
    "        solver_input['lbg'] = lbg\n",
    "        solver_input['ubg'] = ubg\n",
    "\n",
    "        solver_output = solver(**solver_input)\n",
    "\n",
    "        sol = solver_output['x']\n",
    "\n",
    "        sol_evalf = np.squeeze(evalf(sol))\n",
    "        u = sol_evalf[-du*mpc_T:].reshape(-1,du)\n",
    "        x = sol_evalf[:-du*mpc_T].reshape(-1,dx)\n",
    "\n",
    "        return x, u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, mpc_H, mpc_T, O, K):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        input_size = 3 + mpc_H\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, mpc_T*O)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.output_activation = nn.Tanh()\n",
    "        self.K = K\n",
    "        self.O = O\n",
    "        self.mpc_T = mpc_T\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.output_activation(x) * self.K\n",
    "        x = x.reshape(self.mpc_T, -1, self.O)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_init(BS, dyn, sn=None):\n",
    "    \n",
    "    # If sn!=None, we makesure that we always sample the same set of initial states\n",
    "    # We need that for validation to understand if our model is improving or not\n",
    "    \n",
    "    gen=None\n",
    "    if sn != None:\n",
    "        gen = torch.Generator()\n",
    "        gen.manual_seed(sn)\n",
    "    \n",
    "    di = 1000\n",
    "    sigma_sample = torch.randint(int(1.5*di), int(3.0*di), (BS,1), generator=gen)/di\n",
    "    d_sample = torch.randint(int(-.15*di), int(.15*di), (BS,1), generator=gen)/di\n",
    "    phi_sample = torch.randint(int(-0.08*di), int(0.08*di), (BS,1), generator=gen)/di\n",
    "    v_sample = torch.randint(0, int(.22*di), (BS,1), generator=gen)/di\n",
    "    \n",
    "    sigma_diff_sample = torch.zeros((BS,1))\n",
    "    \n",
    "    d_pen = dyn.penalty_d(d_sample)\n",
    "    v_pen = dyn.penalty_v(v_sample)\n",
    "    \n",
    "    x_init_sample = torch.hstack((\n",
    "        sigma_sample, d_sample, phi_sample, v_sample, \n",
    "        sigma_sample, sigma_diff_sample, d_pen, v_pen))   \n",
    "    \n",
    "    return x_init_sample\n",
    "\n",
    "def get_curve_hor_from_x(x, track_coord, H_curve):\n",
    "    idx_track_batch = ((x[:,0]-track_coord[[2],:].T)**2).argmin(0)\n",
    "    idcs_track_batch = idx_track_batch[:, None] + torch.arange(H_curve)\n",
    "    curvs = track_coord[4,idcs_track_batch].float()\n",
    "    return curvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrenetKinBicycleDx(nn.Module):\n",
    "    def __init__(self, track_coordinates, params, dev):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = params\n",
    "\n",
    "        # states: sigma, d, phi, v (4) + sigma_0, sigma_diff (2) + d_pen (1) + v_ub (1)\n",
    "        self.n_state = 4+2+1+1\n",
    "        print('Number of states:', self.n_state)\n",
    "        \n",
    "        self.n_ctrl = 2 # control: a, delta\n",
    "\n",
    "        self.track_coordinates = track_coordinates.to(dev)\n",
    "\n",
    "        # everything to calculate curvature\n",
    "        self.track_sigma = self.track_coordinates[2,:]\n",
    "        self.track_curv = self.track_coordinates[4,:]\n",
    "\n",
    "        self.track_curv_shift = torch.empty(self.track_curv.size()).to(dev)\n",
    "        self.track_curv_shift[1:] = self.track_curv[0:-1]\n",
    "        self.track_curv_shift[0] = self.track_curv[-1]\n",
    "        self.track_curv_diff = self.track_curv - self.track_curv_shift\n",
    "\n",
    "        self.mask = torch.where(torch.absolute(self.track_curv_diff) < 0.1, False, True)\n",
    "        self.sigma_f = self.track_sigma[self.mask]\n",
    "        self.curv_f = self.track_curv_diff[self.mask]\n",
    "     \n",
    "        self.l_r = params[0]\n",
    "        self.l_f = params[1]\n",
    "        \n",
    "        self.track_width = params[2]\n",
    "        \n",
    "        self.delta_threshold_rad = np.pi\n",
    "        self.dt = params[3]\n",
    "\n",
    "        self.smooth_curve = params[4]\n",
    "        \n",
    "        self.v_max = params[5]\n",
    "        \n",
    "        self.delta_max = params[6]\n",
    "        \n",
    "        self.factor_pen = 10000.\n",
    "                \n",
    "        \n",
    "        \n",
    "    def curv(self, sigma):\n",
    "\n",
    "        num_sf = self.sigma_f.size()\n",
    "        num_s = sigma.size()\n",
    "\n",
    "        sigma_f_mat = self.sigma_f.repeat(num_s[0],1)\n",
    "\n",
    "        sigma_shifted = sigma.reshape(-1,1) - sigma_f_mat\n",
    "        curv_unscaled = torch.sigmoid(self.smooth_curve*sigma_shifted)\n",
    "        curv = (curv_unscaled@(self.curv_f.reshape(-1,1))).type(torch.float)\n",
    "\n",
    "        return curv.reshape(-1)\n",
    "    \n",
    "    \n",
    "    def penalty_d(self, d):  \n",
    "        overshoot_pos = (d - 0.35*self.track_width).clamp(min=0)\n",
    "        overshoot_neg = (-d - 0.35*self.track_width).clamp(min=0)\n",
    "        penalty_pos = torch.exp(overshoot_pos) - 1\n",
    "        penalty_neg = torch.exp(overshoot_neg) - 1 \n",
    "        return self.factor_pen*(penalty_pos + penalty_neg)\n",
    "    \n",
    "    def penalty_v(self, v):          \n",
    "        overshoot_pos = (v - self.v_max).clamp(min=0)\n",
    "        overshoot_neg = (-v + 0.001).clamp(min=0)\n",
    "        penalty_pos = torch.exp(overshoot_pos) - 1\n",
    "        penalty_neg = torch.exp(overshoot_neg) - 1 \n",
    "        return self.factor_pen*(penalty_pos + penalty_neg)\n",
    "    \n",
    "    def penalty_delta(self, delta):          \n",
    "        overshoot_pos = (delta - self.delta_max).clamp(min=0)\n",
    "        overshoot_neg = (-delta - self.delta_max).clamp(min=0)\n",
    "        penalty_pos = torch.exp(overshoot_pos) - 1\n",
    "        penalty_neg = torch.exp(overshoot_neg) - 1 \n",
    "        return self.factor_pen*(penalty_pos + penalty_neg)\n",
    "    \n",
    "    def forward(self, state, u):\n",
    "        squeeze = state.ndimension() == 1\n",
    "        if squeeze:\n",
    "            state = state.unsqueeze(0)\n",
    "            u = u.unsqueeze(0)\n",
    "        if state.is_cuda and not self.params.is_cuda:\n",
    "            self.params = self.params.cuda()\n",
    "\n",
    "\n",
    "        a, delta = torch.unbind(u, dim=1)\n",
    "\n",
    "        sigma, d, phi, v, sigma_0, sigma_diff, d_pen, v_ub = torch.unbind(state, dim=1)\n",
    "        \n",
    "        beta = torch.atan(self.l_r/(self.l_r+self.l_f)*torch.tan(delta))       \n",
    "        k = self.curv(sigma)\n",
    "\n",
    "        dsigma = v*(torch.cos(phi+beta)/(1.-k*d))\n",
    "        dd = v*torch.sin(phi+beta)\n",
    "        dphi = v/self.l_f*torch.sin(beta)-k*v*(torch.cos(phi+beta)/(1-k*d))       \n",
    "        \n",
    "        dv = a      \n",
    "\n",
    "        sigma = sigma + self.dt * dsigma\n",
    "        d = d + self.dt * dd\n",
    "        phi = phi + self.dt * dphi\n",
    "        v = v + self.dt * dv \n",
    "        \n",
    "        sigma_diff = sigma - sigma_0 \n",
    "                \n",
    "        d_pen = self.penalty_d(d)        \n",
    "        v_ub = self.penalty_v(v)\n",
    "\n",
    "        state = torch.stack((sigma, d, phi, v, sigma_0, sigma_diff, d_pen, v_ub), 1)\n",
    "        \n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_casadi(q_np,p_np,x0_np,dx,du,control):\n",
    "    \n",
    "    x_curr_opt, u_curr_opt = control.mpc_casadi(q_np,p_np,x0_np,dx,du)\n",
    "\n",
    "    sigzero_curr_opt = np.expand_dims(x_curr_opt[[0],0].repeat(mpc_T+1), 1)\n",
    "    sigsiff_curr_opt = x_curr_opt[:,[0]]-x_curr_opt[0,0]\n",
    "\n",
    "    x_curr_opt_plus = np.concatenate((\n",
    "        x_curr_opt,sigzero_curr_opt,sigsiff_curr_opt), axis = 1)\n",
    "\n",
    "    x_star = x_curr_opt_plus[:-1]\n",
    "    u_star = u_curr_opt\n",
    "    \n",
    "    return x_star, u_star\n",
    "\n",
    "\n",
    "\n",
    "def q_and_p(mpc_T, q_p_pred, Q_manual, p_manual):\n",
    "    # Cost order: \n",
    "    # [for casadi] sigma_diff, d, phi, v, a, delta\n",
    "    # [for model]  sigma, d, phi, v, sigma_0, sigma_diff, d_pen, v_pen, a, delta\n",
    "    \n",
    "    mpc_T, BS, _ = q_p_pred.shape \n",
    "    \n",
    "    e = 1e-8\n",
    "    \n",
    "    q = e*torch.ones((mpc_T,BS,10)) + torch.tensor(Q_manual).unsqueeze(1).float()\n",
    "    p = torch.zeros((mpc_T,BS,10)) + torch.tensor(p_manual).unsqueeze(1).float()\n",
    "\n",
    "    #sigma_diff\n",
    "    #q[:,:,5] = q_p_pred[:,:,0].clamp(e)\n",
    "    p[:,:,5] = p[:,:,5] + q_p_pred[:,:,0]\n",
    "    \n",
    "    #d\n",
    "    #q[:,:,1] = q_p_pred[:,:,1].clamp(e)\n",
    "    p[:,:,1] = p[:,:,1] + q_p_pred[:,:,1]    \n",
    "    \n",
    "    return q, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_curve = 100.\n",
    "\n",
    "dt = 0.04\n",
    "\n",
    "mpc_T = 30\n",
    "mpc_H = 60\n",
    "\n",
    "l_r = 0.2\n",
    "l_f = 0.2\n",
    "\n",
    "v_max = 2.5\n",
    "\n",
    "delta_max = 0.6\n",
    "\n",
    "a_max = 2.\n",
    "\n",
    "track_density = 300\n",
    "track_width = 0.5\n",
    "t_track = 0.3\n",
    "init_track = [0,0,0]\n",
    "\n",
    "max_p = 100 \n",
    "\n",
    "params = torch.tensor([l_r, l_f, track_width, dt, k_curve, v_max, delta_max, a_max, mpc_T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = simple_track_generator.trackGenerator(track_density,track_width)\n",
    "track_name = 'DEMO_TRACK'\n",
    "\n",
    "track_function = {\n",
    "    'DEMO_TRACK'    : track_functions.demo_track,\n",
    "    'HARD_TRACK'    : track_functions.hard_track,\n",
    "    'LONG_TRACK'    : track_functions.long_track,\n",
    "    'LUCERNE_TRACK' : track_functions.lucerne_track,\n",
    "    'BERN_TRACK'    : track_functions.bern_track,\n",
    "    'INFINITY_TRACK': track_functions.infinity_track,\n",
    "    'SNAIL_TRACK'   : track_functions.snail_track\n",
    "}.get(track_name, track_functions.demo_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_function(gen, t_track, init_track)\n",
    "gen.populatePointsAndArcLength()\n",
    "gen.centerTrack()\n",
    "track_coord = torch.from_numpy(np.vstack(\n",
    "    [gen.xCoords, \n",
    "     gen.yCoords, \n",
    "     gen.arcLength, \n",
    "     gen.tangentAngle, \n",
    "     gen.curvature]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states: 8\n"
     ]
    }
   ],
   "source": [
    "true_dx = FrenetKinBicycleDx(track_coord, params, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.tensor([0.0, 0.1, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0])\n",
    "u0 = torch.tensor([0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx=4\n",
    "du=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 16\n",
    "u_lower = torch.tensor([-a_max, -delta_max]).unsqueeze(0).unsqueeze(0).repeat(mpc_T, BS, 1)#.to(dev)\n",
    "u_upper = torch.tensor([a_max, delta_max]).unsqueeze(0).unsqueeze(0).repeat(mpc_T, BS, 1)#.to(dev)\n",
    "u_init= torch.tensor([0.1, 0.0]).unsqueeze(0).unsqueeze(0).repeat(mpc_T, BS, 1)#.to(device)\n",
    "eps=0.01\n",
    "lqr_iter = 50\n",
    "\n",
    "grad_method = GradMethods.AUTO_DIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN(mpc_H, mpc_T, 2, max_p)\n",
    "opt = torch.optim.RMSprop(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "control = CasadiControl(track_coord, params)\n",
    "Q_manual = np.repeat(np.expand_dims(np.array([0, 20, 5, 0, 0, 0, 0, 0, 0, 0]), 0), mpc_T, 0)\n",
    "p_manual = np.repeat(np.expand_dims(np.array([0, 0, 0, 0, 0, -.5, 0, 0, 0, 0]), 0), mpc_T, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_casadi = [5,1,2,3,8,9] # This is only to match the indices of Q from model to casadi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Progress:  0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for it in range(50):\n",
    "\n",
    "    x0 = sample_init(BS, true_dx)\n",
    "    curv = get_curve_hor_from_x(x0, track_coord, mpc_H)\n",
    "    inp = torch.hstack((x0[:,1:4], curv))\n",
    "    q_p_pred = model(inp)\n",
    "\n",
    "    q, p = q_and_p(mpc_T, q_p_pred, Q_manual, p_manual)\n",
    "    Q = torch.diag_embed(q, offset=0, dim1=-2, dim2=-1)\n",
    "    \n",
    "    pred_x, pred_u, pred_objs = mpc.MPC(\n",
    "                true_dx.n_state, true_dx.n_ctrl, mpc_T,\n",
    "                u_lower=u_lower, u_upper=u_upper, u_init=u_init,\n",
    "                lqr_iter=lqr_iter,\n",
    "                verbose=0,\n",
    "                exit_unconverged=False,\n",
    "                detach_unconverged=False,\n",
    "                linesearch_decay=.8,\n",
    "                max_linesearch_iter=4,\n",
    "                grad_method=grad_method,\n",
    "                eps=eps,\n",
    "                n_batch=None,\n",
    "            )(x0, QuadCost(Q, p), true_dx)\n",
    "    \n",
    "    # It would be good if we could solve with casadi in batches\n",
    "    x_manual = np.zeros((mpc_T, BS, 6))\n",
    "    for bb in range(BS):\n",
    "        x_star, u_star = solve_casadi(\n",
    "            Q_manual[:,idx_to_casadi].T, p_manual[:,idx_to_casadi].T,\n",
    "            x0[bb].detach().numpy(),dx,du,control)\n",
    "        x_manual[:, bb] = x_star\n",
    "    \n",
    "    progress = (pred_x[-1,:,5]- torch.tensor(x_manual[-1,:,5]))\n",
    "    loss = -progress.mean() \\\n",
    "    + true_dx.penalty_d(pred_x[:,:,1]).sum(0).mean() \\\n",
    "    + true_dx.penalty_v(pred_x[:,:,3]).sum(0).mean()\n",
    "      \n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()  \n",
    "    \n",
    "    # V A L I D A T I O N   (only casadi) \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # This sampling should bring always the same set of initial states\n",
    "        x0_val = sample_init(BS, true_dx, sn=0)\n",
    "        \n",
    "        # It would be good if we could solve with casadi in batches\n",
    "        # instead of going through the for loop\n",
    "        x_pred_casadi = np.zeros((mpc_T, BS, 6))\n",
    "        for bb in range(BS):\n",
    "            q_val = q[:,bb,idx_to_casadi].detach().numpy().T\n",
    "            p_val = p[:,bb,idx_to_casadi].detach().numpy().T\n",
    "            x_val, u_val = solve_casadi(q_val, p_val,\n",
    "                x0_val[bb].detach().numpy(),dx,du,control)\n",
    "            x_pred_casadi[:,bb] = x_val\n",
    "            \n",
    "        x_manual = np.zeros((mpc_T, BS, 6))\n",
    "        for bb in range(BS):\n",
    "            x_star, u_star = solve_casadi(\n",
    "                Q_manual[:,idx_to_casadi].T, p_manual[:,idx_to_casadi].T,\n",
    "                x0_val[bb].detach().numpy(),dx,du,control)\n",
    "            x_manual[:, bb] = x_star\n",
    "\n",
    "        progress_val = x_pred_casadi[-1,:,5] - x_manual[-1,:,5]\n",
    "    \n",
    "    #print(round(progress.mean().item(), 3))    \n",
    "    #print(q_p_pred.mean(0).mean(0))\n",
    "    \n",
    "    print(f'{it}: Progress: ', round(progress_val.mean(), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pao_env",
   "language": "python",
   "name": "pao_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
