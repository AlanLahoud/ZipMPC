{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function, Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Comment these lines if your MPC is in the current directory.\n",
    "# Otherwise modify to the directory.\n",
    "import sys\n",
    "sys.path.append('./../mpc.pytorch/')\n",
    "\n",
    "\n",
    "from mpc import mpc\n",
    "from mpc.mpc import GradMethods, QuadCost, LinDx\n",
    "from mpc.dynamics import NNDynamics\n",
    "import mpc.util as eutil\n",
    "from mpc.env_dx import pendulum, cartpole, frenet_kin_bicycle\n",
    "from mpc.track.src import simple_track_generator, track_functions\n",
    "\n",
    "\n",
    "#import sys\n",
    "#from IPython.core import ultratb\n",
    "#sys.excepthook = ultratb.FormattedTB(mode='Verbose',\n",
    "#     color_scheme='Linux', call_pdb=1)\n",
    "\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import pickle as pkl\n",
    "import collections\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to create a track \n",
    "\n",
    "track_density = 300\n",
    "track_width = 0.5\n",
    "gen = simple_track_generator.trackGenerator(track_density,track_width)\n",
    "track_name = 'DEMO_TRACK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.3\n",
    "init = [0,0,0]\n",
    "\n",
    "track_function = {\n",
    "    'DEMO_TRACK'    : track_functions.demo_track,\n",
    "    'HARD_TRACK'    : track_functions.hard_track,\n",
    "    'LONG_TRACK'    : track_functions.long_track,\n",
    "    'LUCERNE_TRACK' : track_functions.lucerne_track,\n",
    "    'BERN_TRACK'    : track_functions.bern_track,\n",
    "    'INFINITY_TRACK': track_functions.infinity_track,\n",
    "    'SNAIL_TRACK'   : track_functions.snail_track\n",
    "}.get(track_name, track_functions.demo_track)\n",
    "    \n",
    "track_function(gen, t, init)\n",
    "    \n",
    "gen.populatePointsAndArcLength()\n",
    "gen.centerTrack()\n",
    "\n",
    "track_coord = torch.from_numpy(np.vstack([gen.xCoords, gen.yCoords, gen.arcLength, gen.tangentAngle, gen.curvature]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "softplus_op = torch.nn.Softplus(10)\n",
    "\n",
    "def sample_xinit(n_batch):\n",
    "    def uniform(shape, low, high):\n",
    "        r = high-low\n",
    "        return torch.rand(shape)*r+low\n",
    "\n",
    "    sigma = uniform(n_batch, 0.01, 2.)\n",
    "    d = uniform(n_batch, -0.1, 0.1)\n",
    "    phi = uniform(n_batch, -0.40*np.pi, 0.40*np.pi)\n",
    "    v = uniform(n_batch, 0., 0.2)\n",
    "    d_lb = softplus_op(-d-0.5*track_width)\n",
    "    d_ub = softplus_op(d-0.5*track_width)\n",
    "    xinit = torch.stack((sigma, d, phi, v, d_lb, d_ub), dim=1)\n",
    "\n",
    "    return xinit\n",
    "\n",
    "true_dx = frenet_kin_bicycle.FrenetKinBicycleDx(track_coord)\n",
    "mpc_T = 15\n",
    "n_batch = 8\n",
    "\n",
    "# Added here the bounds of U\n",
    "u_lower = torch.tensor([-2., -1.]).unsqueeze(0).unsqueeze(0).repeat(mpc_T, n_batch, 1)\n",
    "u_upper = torch.tensor([2., 1.]).unsqueeze(0).unsqueeze(0).repeat(mpc_T, n_batch, 1)\n",
    "\n",
    "n_state = true_dx.n_state\n",
    "n_ctrl = true_dx.n_ctrl\n",
    "\n",
    "u_init=None\n",
    "eps = 1\n",
    "lqr_iter = 500\n",
    "grad_method = GradMethods.AUTO_DIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each mpc returns a prediction of the states and the inputs over the horizon for all batches and all dimensions,\n",
    "# they are stored in the following order pred_x = [horizon,batch, dimension].\n",
    "# To penalize a control behaviour that does not enforce enough progress within a horizon we can try to chose \n",
    "# our loss as -pred_x[mpc_T-1,:,0]\n",
    "\n",
    "def get_loss_progress(x_init, dx, _Q, _p, mpc_T=mpc_T):    \n",
    "        \n",
    "        pred_x, pred_u, pred_objs = mpc.MPC(\n",
    "            dx.n_state, dx.n_ctrl, mpc_T,\n",
    "            u_lower=u_lower, u_upper=u_upper, u_init=u_init,\n",
    "            lqr_iter=lqr_iter,\n",
    "            verbose=0,\n",
    "            exit_unconverged=False,\n",
    "            detach_unconverged=True,\n",
    "            linesearch_decay=dx.linesearch_decay,\n",
    "            max_linesearch_iter=dx.max_linesearch_iter,\n",
    "            grad_method=grad_method,\n",
    "            eps=0.5,\n",
    "            n_batch=n_batch,\n",
    "        )(x_init, QuadCost(_Q, _p), dx)\n",
    "        \n",
    "        #I added the second term to account the initial state (to kind of normalize the progress)\n",
    "        progress_loss = torch.mean(-pred_x[mpc_T-1,:,0] + pred_x[0,:,0])\n",
    "        \n",
    "        #penalty_loss = pred_x[]\n",
    "            \n",
    "        return progress_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = []\n",
    "learn_q_logit_state = torch.ones(n_state-2, requires_grad=True).to(device)\n",
    "learn_q_logit_input = torch.ones(n_ctrl, requires_grad=True).to(device)\n",
    "learn_p_state = torch.zeros(n_state-2, requires_grad=True).to(device)\n",
    "learn_p_input = torch.zeros(n_ctrl, requires_grad=True).to(device)\n",
    "params1 += [learn_q_logit_state, learn_q_logit_input, learn_p_state, learn_p_input]\n",
    "env_params = true_dx.params\n",
    "q_penalty = .01*torch.ones(2).to(device)\n",
    "p_penalty = 10*torch.ones(2).to(device)\n",
    "track_coord = track_coord.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn_q_logit = torch.ones_like(true_q, requires_grad=True).to(device)\n",
    "#learn_p = torch.zeros_like(true_p, requires_grad=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = [{\n",
    "            'params': params1,\n",
    "            'lr': 2e-3,\n",
    "            'alpha': 0.99,\n",
    "            }]\n",
    "dx = true_dx.__class__(track_coord,env_params)\n",
    "\n",
    "opt = optim.RMSprop(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0  Progression with MPC_T= 15 :  0.0413\n",
      "Batch: 1  Progression with MPC_T= 15 :  0.0349\n",
      "Batch: 2  Progression with MPC_T= 15 :  0.0625\n",
      "Batch: 3  Progression with MPC_T= 15 :  0.0548\n",
      "Batch: 4  Progression with MPC_T= 15 :  0.065\n",
      "Batch: 5  Progression with MPC_T= 15 :  0.0396\n",
      "Batch: 6  Progression with MPC_T= 15 :  0.0786\n",
      "Batch: 7  Progression with MPC_T= 15 :  0.0419\n",
      "Batch: 8  Progression with MPC_T= 15 :  0.0449\n",
      "Batch: 9  Progression with MPC_T= 15 :  0.0473\n",
      "Batch: 10  Progression with MPC_T= 15 :  0.0487\n",
      "Batch: 11  Progression with MPC_T= 15 :  0.0742\n",
      "Batch: 12  Progression with MPC_T= 15 :  0.0273\n",
      "Batch: 13  Progression with MPC_T= 15 :  0.0736\n",
      "Batch: 14  Progression with MPC_T= 15 :  0.0711\n",
      "Batch: 15  Progression with MPC_T= 15 :  0.0553\n",
      "Batch: 16  Progression with MPC_T= 15 :  0.0877\n",
      "Batch: 17  Progression with MPC_T= 15 :  0.0829\n",
      "Batch: 18  Progression with MPC_T= 15 :  0.0567\n",
      "Batch: 19  Progression with MPC_T= 15 :  0.0859\n",
      "Batch: 20  Progression with MPC_T= 15 :  0.0922\n",
      "Batch: 21  Progression with MPC_T= 15 :  0.0555\n",
      "Batch: 22  Progression with MPC_T= 15 :  0.0709\n",
      "Batch: 23  Progression with MPC_T= 15 :  0.0753\n",
      "Batch: 24  Progression with MPC_T= 15 :  0.0958\n",
      "Batch: 25  Progression with MPC_T= 15 :  0.0791\n",
      "Batch: 26  Progression with MPC_T= 15 :  0.0572\n",
      "Batch: 27  Progression with MPC_T= 15 :  0.103\n",
      "Batch: 28  Progression with MPC_T= 15 :  0.0958\n",
      "Batch: 29  Progression with MPC_T= 15 :  0.1041\n",
      "Batch: 30  Progression with MPC_T= 15 :  0.1135\n",
      "Batch: 31  Progression with MPC_T= 15 :  0.1034\n",
      "Batch: 32  Progression with MPC_T= 15 :  0.1063\n",
      "Batch: 33  Progression with MPC_T= 15 :  0.1077\n",
      "Batch: 34  Progression with MPC_T= 15 :  0.0691\n",
      "Batch: 35  Progression with MPC_T= 15 :  0.0902\n",
      "Batch: 36  Progression with MPC_T= 15 :  0.0982\n",
      "Batch: 37  Progression with MPC_T= 15 :  0.1317\n",
      "Batch: 38  Progression with MPC_T= 15 :  0.1274\n",
      "Batch: 39  Progression with MPC_T= 15 :  0.1221\n",
      "Batch: 40  Progression with MPC_T= 15 :  0.0852\n",
      "Batch: 41  Progression with MPC_T= 15 :  0.1016\n",
      "Batch: 42  Progression with MPC_T= 15 :  0.1474\n",
      "Batch: 43  Progression with MPC_T= 15 :  0.0815\n",
      "Batch: 44  Progression with MPC_T= 15 :  0.1422\n",
      "Batch: 45  Progression with MPC_T= 15 :  0.14\n",
      "Batch: 46  Progression with MPC_T= 15 :  0.1318\n",
      "Batch: 47  Progression with MPC_T= 15 :  0.126\n",
      "Batch: 48  Progression with MPC_T= 15 :  0.1554\n",
      "Batch: 49  Progression with MPC_T= 15 :  0.142\n",
      "Batch: 50  Progression with MPC_T= 15 :  0.138\n",
      "Batch: 51  Progression with MPC_T= 15 :  0.136\n",
      "Batch: 52  Progression with MPC_T= 15 :  0.1349\n",
      "Batch: 53  Progression with MPC_T= 15 :  0.1258\n",
      "Batch: 54  Progression with MPC_T= 15 :  0.1321\n",
      "Batch: 55  Progression with MPC_T= 15 :  0.1515\n",
      "Batch: 56  Progression with MPC_T= 15 :  0.1335\n",
      "Batch: 57  Progression with MPC_T= 15 :  0.1819\n",
      "Batch: 58  Progression with MPC_T= 15 :  0.1898\n",
      "Batch: 59  Progression with MPC_T= 15 :  0.2054\n",
      "Batch: 60  Progression with MPC_T= 15 :  0.1785\n",
      "Batch: 61  Progression with MPC_T= 15 :  0.1619\n",
      "Batch: 62  Progression with MPC_T= 15 :  0.1643\n",
      "Batch: 63  Progression with MPC_T= 15 :  0.2133\n",
      "Batch: 64  Progression with MPC_T= 15 :  0.1797\n",
      "Batch: 65  Progression with MPC_T= 15 :  0.1675\n",
      "Batch: 66  Progression with MPC_T= 15 :  0.1904\n",
      "Batch: 67  Progression with MPC_T= 15 :  0.1858\n",
      "Batch: 68  Progression with MPC_T= 15 :  0.2145\n",
      "Batch: 69  Progression with MPC_T= 15 :  0.18\n",
      "Batch: 70  Progression with MPC_T= 15 :  0.1805\n",
      "Batch: 71  Progression with MPC_T= 15 :  0.1829\n",
      "Batch: 72  Progression with MPC_T= 15 :  0.1861\n",
      "Batch: 73  Progression with MPC_T= 15 :  0.2053\n",
      "Batch: 74  Progression with MPC_T= 15 :  0.1784\n",
      "Batch: 75  Progression with MPC_T= 15 :  0.177\n",
      "Batch: 76  Progression with MPC_T= 15 :  0.2436\n",
      "Batch: 77  Progression with MPC_T= 15 :  0.2385\n",
      "Batch: 78  Progression with MPC_T= 15 :  0.2318\n",
      "Batch: 79  Progression with MPC_T= 15 :  0.2671\n",
      "Batch: 80  Progression with MPC_T= 15 :  0.2729\n",
      "Batch: 81  Progression with MPC_T= 15 :  0.2139\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8d81ea39b660>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_xinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#im_loss = get_loss_cost(x_init, dx, Q_batch, p_batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mim_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ea0c8aaab5b3>\u001b[0m in \u001b[0;36mget_loss_progress\u001b[0;34m(x_init, dx, _Q, _p, mpc_T)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_loss_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpc_T\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmpc_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         pred_x, pred_u, pred_objs = mpc.MPC(\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mdx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_ctrl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmpc_T\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mu_lower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mu_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_upper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mu_upper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mu_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research/Code/race_application/./../mpc.pytorch/mpc/mpc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_init, cost, dx)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                 F, f = self.linearize_dynamics(\n\u001b[0m\u001b[1;32m    256\u001b[0m                     x, util.detach_maybe(u), dx, diff=False)\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Research/Code/race_application/./../mpc.pytorch/mpc/mpc.py\u001b[0m in \u001b[0;36mlinearize_dynamics\u001b[0;34m(self, x, u, dynamics, diff)\u001b[0m\n\u001b[1;32m    540\u001b[0m                         \u001b[0mRt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m                             Rj, Sj = torch.autograd.grad(\n\u001b[0m\u001b[1;32m    543\u001b[0m                                 \u001b[0mnew_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mut\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                                 retain_graph=True)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_vmap_internals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_none_pass_through\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    277\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(150):\n",
    "\n",
    "    q = torch.cat((learn_q_logit_state,q_penalty,learn_q_logit_input),dim=0)\n",
    "    p = torch.cat((learn_p_state,p_penalty,learn_p_input), dim=0)\n",
    "    #print(q)\n",
    "\n",
    "    Q_batch = torch.diag(q).unsqueeze(0).unsqueeze(0).repeat(\n",
    "                mpc_T, n_batch, 1, 1\n",
    "            )\n",
    "    p_batch = p.unsqueeze(0).repeat(mpc_T, n_batch, 1)\n",
    "\n",
    "    x_init = sample_xinit(n_batch).to(device)\n",
    "    #im_loss = get_loss_cost(x_init, dx, Q_batch, p_batch)\n",
    "    im_loss = get_loss_progress(x_init, dx, Q_batch, p_batch)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    im_loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    print('Batch:', i , ' Progression with MPC_T=',mpc_T ,': ', -round(im_loss.item(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can choose the number of samples we want to test (number of initial states)\n",
    "N_test = 1\n",
    "\n",
    "# Whatever I wrote below might be wrong, we have to see if we really can change the mpc_T to Test, \n",
    "# it gives weird results sometimes.\n",
    "# Here we can choose the mpc_T in the test time, which can be much higher than in the training.\n",
    "# Ideally, we would like to have the whole lap here, I guess. But we need to fix the warnings/errors before.\n",
    "mpc_T_test = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init_test = sample_xinit(N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below you can put any initial state you want (any that make sense)\n",
    "x_init_test = torch.tensor([[1.6, 0.1, -0.8, 0.1,softplus_op(torch.Tensor([-0.1-0.5*track_width])), softplus_op(torch.Tensor([-0.1-0.5*track_width]))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_test = torch.diag(q).unsqueeze(0).unsqueeze(0).repeat(\n",
    "                mpc_T_test, N_test, 1, 1\n",
    "            )\n",
    "p_test = p.unsqueeze(0).repeat(mpc_T_test, N_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_q, true_p = true_dx.get_true_obj()\n",
    "true_q = torch.Tensor([ 0.,  3.,  1.,  0., 0., 0., 1., 2.])\n",
    "true_p = torch.Tensor([ -2.,  0.,  0.,  0., 100., 100.,  -1,  0.])\n",
    "\n",
    "true_q = true_q.to(device)\n",
    "true_p = true_p.to(device)\n",
    "\n",
    "expert_Q = torch.diag(true_q).unsqueeze(0).unsqueeze(0).repeat(\n",
    "            mpc_T_test, N_test, 1, 1\n",
    "        )\n",
    "expert_p = true_p.unsqueeze(0).repeat(mpc_T_test, N_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added here the bounds of U\n",
    "u_lower_test = torch.tensor([-2., -1.]).unsqueeze(0).unsqueeze(0).repeat(mpc_T_test, N_test, 1)\n",
    "u_upper_test = torch.tensor([2., 1.]).unsqueeze(0).unsqueeze(0).repeat(mpc_T_test, N_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] pnqp warning: Did not converge\n",
      "[WARNING] pnqp warning: Did not converge\n",
      "[WARNING] pnqp warning: Did not converge\n",
      "[WARNING] pnqp warning: Did not converge\n",
      "[WARNING] pnqp warning: Did not converge\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n"
     ]
    }
   ],
   "source": [
    "x_mpc_test, u_mpc_test, objs_mpc_test = mpc.MPC(\n",
    "            n_state, n_ctrl, mpc_T_test,\n",
    "            u_lower=u_lower_test, u_upper=u_upper_test, u_init=u_init,\n",
    "            lqr_iter=lqr_iter,\n",
    "            verbose=0,\n",
    "            exit_unconverged=False,\n",
    "            detach_unconverged=True,\n",
    "            linesearch_decay=dx.linesearch_decay,\n",
    "            max_linesearch_iter=dx.max_linesearch_iter,\n",
    "            grad_method=grad_method,\n",
    "            eps=eps,\n",
    "            n_batch=N_test,\n",
    "        )(x_init_test, QuadCost(expert_Q, expert_p), dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frenet_to_cartesian(point_f, ref_path):\n",
    "    \n",
    "    def get_nearest_index(point_f, ref_path):\n",
    "        return ((point_f[0] - ref_path[2,:])**2).argmin()\n",
    "    \n",
    "    def compute_x_coord(point_f, ref_path, nearest_index):\n",
    "        return ref_path[0,nearest_index] - point_f[1]*torch.sin(ref_path[3,nearest_index])\n",
    "    \n",
    "    def compute_y_coord(point_f, ref_path, nearest_index):\n",
    "        return ref_path[1,nearest_index] + point_f[1]*torch.cos(ref_path[3,nearest_index])\n",
    "    \n",
    "    nearest_index = get_nearest_index(point_f, ref_path)\n",
    "    x = compute_x_coord(point_f, ref_path, nearest_index)\n",
    "    y = compute_y_coord(point_f, ref_path, nearest_index)\n",
    "    \n",
    "    return torch.tensor([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "\n",
    "for i in range(mpc_T_test):\n",
    "    xy = frenet_to_cartesian(x_mpc_test[i,0,:2], track_coord)\n",
    "    x_list.append(xy[0].numpy())\n",
    "    y_list.append(xy[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.array(x_list)\n",
    "y_plot = np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6193, 0.8438], grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_mpc_test.max(0)[0].max(0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImageTk' from 'PIL' (/usr/lib/python3/dist-packages/PIL/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a46f279f77b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotPoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#gen.pointAtArcLength(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#gen.writePointsToYaml('../tracks/' + track_name + '.yaml', track_density)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msubplots\u001b[0;34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m     \"\"\"\n\u001b[0;32m-> 1442\u001b[0;31m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfig_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m     axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,\n\u001b[1;32m   1444\u001b[0m                        \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplot_kw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubplot_kw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Don't modify *func*'s signature, as boilerplate.py needs it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mfigure\u001b[0;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[1;32m    781\u001b[0m                 RuntimeWarning)\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m         manager = new_figure_manager(\n\u001b[0m\u001b[1;32m    784\u001b[0m             \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mfacecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medgecolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mnew_figure_manager\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnew_figure_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;34m\"\"\"Create a new figure manager instance.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0m_warn_if_gui_out_of_main_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_backend_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_figure_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m_warn_if_gui_out_of_main_thread\u001b[0;34m()\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_warn_if_gui_out_of_main_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0mwarn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_get_required_interactive_framework\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_backend_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreading\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_native_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;31m# This compares native thread ids because even if Python-level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36m_get_backend_mod\u001b[0;34m()\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;31m# will (re)import pyplot and then call switch_backend if we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;31m# resolve the auto sentinel)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mswitch_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_backend_mod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mswitch_backend\u001b[0;34m(newbackend)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     backend_mod = importlib.import_module(\n\u001b[0m\u001b[1;32m    266\u001b[0m         cbook._backend_module_name(newbackend))\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/backends/backend_tkagg.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_backend_tk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend_agg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_backend_tk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_BackendTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFigureCanvasTk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m from ._backend_tk import (  # noqa: F401 # pylint: disable=W0611\n\u001b[1;32m      5\u001b[0m     FigureManagerTk, NavigationToolbar2Tk)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/backends/_backend_tk.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageTk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ImageTk' from 'PIL' (/usr/lib/python3/dist-packages/PIL/__init__.py)"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,5), dpi=120)\n",
    "gen.plotPoints(ax)\n",
    "#gen.pointAtArcLength(0)\n",
    "#gen.writePointsToYaml('../tracks/' + track_name + '.yaml', track_density)\n",
    "\n",
    "ax.scatter(x_plot, y_plot, s=4, color='red')\n",
    "\n",
    "print('x_init: ' + str(gen.xCoords[0]))\n",
    "print('y_init: ' + str(gen.yCoords[0]))\n",
    "print('yaw_init: ' + str(gen.tangentAngle[0]))\n",
    "print('Total Arc Length: ' + str(gen.arcLength[-1]/2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
