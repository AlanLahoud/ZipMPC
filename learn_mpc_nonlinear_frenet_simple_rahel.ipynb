{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function, Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Comment these lines if your MPC is in the current directory.\n",
    "# Otherwise modify to the directory.\n",
    "#import sys\n",
    "#sys.path.append('./../mpc.pytorch-master/')\n",
    "\n",
    "\n",
    "from mpc import mpc\n",
    "from mpc import casadi_control\n",
    "from mpc.mpc import GradMethods, QuadCost, LinDx\n",
    "#from mpc.dynamics import NNDynamics\n",
    "#import mpc.util as eutil\n",
    "from mpc.env_dx import frenet_kin_bicycle\n",
    "from mpc.track.src import simple_track_generator, track_functions\n",
    "\n",
    "\n",
    "\n",
    "#import sys\n",
    "#from IPython.core import ultratb\n",
    "#sys.excepthook = ultratb.FormattedTB(mode='Verbose',\n",
    "#     color_scheme='Linux', call_pdb=1)\n",
    "\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import pickle as pkl\n",
    "import collections\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to create a track \n",
    "\n",
    "track_density = 300\n",
    "track_width = 0.5\n",
    "v_max = 2\n",
    "gen = simple_track_generator.trackGenerator(track_density,track_width)\n",
    "track_name = 'DEMO_TRACK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.3\n",
    "init = [0,0,0]\n",
    "\n",
    "track_function = {\n",
    "    'DEMO_TRACK'    : track_functions.demo_track,\n",
    "    'HARD_TRACK'    : track_functions.hard_track,\n",
    "    'LONG_TRACK'    : track_functions.long_track,\n",
    "    'LUCERNE_TRACK' : track_functions.lucerne_track,\n",
    "    'BERN_TRACK'    : track_functions.bern_track,\n",
    "    'INFINITY_TRACK': track_functions.infinity_track,\n",
    "    'SNAIL_TRACK'   : track_functions.snail_track\n",
    "}.get(track_name, track_functions.demo_track)\n",
    "    \n",
    "track_function(gen, t, init)\n",
    "    \n",
    "gen.populatePointsAndArcLength()\n",
    "gen.centerTrack()\n",
    "\n",
    "track_coord = torch.from_numpy(np.vstack([gen.xCoords, gen.yCoords, gen.arcLength, gen.tangentAngle, gen.curvature]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "softplus_op = torch.nn.Softplus(10)\n",
    "\n",
    "def sample_xinit(n_batch):\n",
    "    def uniform(shape, low, high):\n",
    "        r = high-low\n",
    "        return torch.rand(shape)*r+low\n",
    "\n",
    "    sigma = uniform(n_batch, 0.01, 2.)\n",
    "    d = uniform(n_batch, -0.1, 0.1)\n",
    "    phi = uniform(n_batch, -0.40*np.pi, 0.40*np.pi)\n",
    "    v = uniform(n_batch, 0., 0.2)\n",
    "    sigma_0 = sigma\n",
    "    sigma_diff = sigma-sigma_0\n",
    "    d_lb = softplus_op(-d-0.5*track_width)\n",
    "    d_ub = softplus_op(d-0.5*track_width)\n",
    "    v_lb = softplus_op(-v + 0)\n",
    "    v_ub = softplus_op(v-v_max)\n",
    "    xinit = torch.stack((sigma, d, phi, v, sigma_0, sigma_diff, d_lb, d_ub, v_lb, v_ub), dim=1)\n",
    "\n",
    "    return xinit\n",
    "\n",
    "true_dx = frenet_kin_bicycle.FrenetKinBicycleDx(track_coord)\n",
    "mpc_T = 15\n",
    "n_batch = 8\n",
    "\n",
    "# Added here the bounds of U\n",
    "u_lower = torch.tensor([-2., -1.]).unsqueeze(0).unsqueeze(0).repeat(mpc_T, n_batch, 1)\n",
    "u_upper = torch.tensor([2., 1.]).unsqueeze(0).unsqueeze(0).repeat(mpc_T, n_batch, 1)\n",
    "\n",
    "n_state = true_dx.n_state\n",
    "print(n_state)\n",
    "n_ctrl = true_dx.n_ctrl\n",
    "\n",
    "u_init=None\n",
    "eps = 1\n",
    "lqr_iter = 500\n",
    "grad_method = GradMethods.AUTO_DIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.1124768e-02  4.2249687e-02 -2.6196527e-01  8.9807473e-02\n",
      "  8.1124768e-02  0.0000000e+00  5.2401917e-03  1.1799859e-02\n",
      "  3.4171075e-02  5.0598709e-10]\n",
      "curv start\n",
      "curv end\n",
      "curv start\n",
      "curv end\n",
      "curv start\n",
      "curv end\n",
      "solve optimization problem\n",
      "This is Ipopt version 3.14.11, running with linear solver MUMPS 5.4.1.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:      304\n",
      "Number of nonzeros in inequality constraint Jacobian.:       30\n",
      "Number of nonzeros in Lagrangian Hessian.............:      240\n",
      "\n",
      "Total number of variables............................:       94\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:       64\n",
      "Total number of inequality constraints...............:       30\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:       30\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  2.4337430e+00 2.62e-01 1.64e+01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  3.8557494e+00 2.19e-01 5.00e+01  -1.0 1.22e+01    -  1.41e-01 1.63e-01h  1\n",
      "   2 -1.4261653e+00 8.11e-04 2.34e+00  -1.0 3.81e-01    -  4.23e-01 1.00e+00f  1\n",
      "   3 -4.6615967e+00 1.18e-03 3.03e-01  -1.0 1.50e+00    -  5.51e-01 1.00e+00f  1\n",
      "   4 -4.8219852e+00 4.90e-06 2.10e-04  -1.7 2.97e-01    -  1.00e+00 1.00e+00f  1\n",
      "   5 -4.8238495e+00 2.52e-07 6.79e-07  -2.5 3.84e-02    -  1.00e+00 1.00e+00h  1\n",
      "   6 -4.8238633e+00 2.33e-09 1.15e-08  -3.8 1.82e-03    -  1.00e+00 1.00e+00h  1\n",
      "   7 -4.8238634e+00 5.11e-12 2.34e-11  -5.7 3.52e-05    -  1.00e+00 1.00e+00h  1\n",
      "   8 -4.8238634e+00 7.84e-16 6.66e-15  -8.6 3.94e-07    -  1.00e+00 1.00e+00h  1\n",
      "\n",
      "Number of Iterations....: 8\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:  -4.8238634121055624e+00   -4.8238634121055624e+00\n",
      "Dual infeasibility......:   6.6613381477509392e-15    6.6613381477509392e-15\n",
      "Constraint violation....:   7.8409501114151681e-16    7.8409501114151681e-16\n",
      "Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   2.5064761456217270e-09    2.5064761456217270e-09\n",
      "Overall NLP error.......:   2.5064761456217270e-09    2.5064761456217270e-09\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 9\n",
      "Number of objective gradient evaluations             = 9\n",
      "Number of equality constraint evaluations            = 9\n",
      "Number of inequality constraint evaluations          = 9\n",
      "Number of equality constraint Jacobian evaluations   = 9\n",
      "Number of inequality constraint Jacobian evaluations = 9\n",
      "Number of Lagrangian Hessian evaluations             = 8\n",
      "Total seconds in IPOPT                               = 0.006\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "       nlp_f  |  20.00us (  2.22us)  17.39us (  1.93us)         9\n",
      "       nlp_g  | 198.00us ( 22.00us) 195.28us ( 21.70us)         9\n",
      "  nlp_grad_f  |  26.00us (  2.60us)  27.42us (  2.74us)        10\n",
      "  nlp_hess_l  | 736.00us ( 92.00us) 736.49us ( 92.06us)         8\n",
      "   nlp_jac_g  | 306.00us ( 30.60us) 306.53us ( 30.65us)        10\n",
      "       total  |   6.04ms (  6.04ms)   6.02ms (  6.02ms)         1\n",
      "[[ 7.28144487e-01  1.41376399e-04]\n",
      " [ 6.95592716e-01  1.08427495e-02]\n",
      " [ 6.65406609e-01  1.95362921e-02]\n",
      " [ 6.37656195e-01  2.63431541e-02]\n",
      " [ 6.12396540e-01  3.13706788e-02]\n",
      " [ 5.89668820e-01  3.47147508e-02]\n",
      " [ 5.69501257e-01  3.64610828e-02]\n",
      " [ 5.51909952e-01  3.66857831e-02]\n",
      " [ 5.36899621e-01  3.54554643e-02]\n",
      " [ 5.24464232e-01  3.28270890e-02]\n",
      " [ 5.14587523e-01  2.88476989e-02]\n",
      " [ 5.07243375e-01  2.35541317e-02]\n",
      " [ 5.02396011e-01  1.69728044e-02]\n",
      " [ 5.00000000e-01  9.11961438e-03]\n",
      " [ 5.00000000e-01 -2.50404115e-20]]\n",
      "[[ 0.08112477  0.04224969 -0.26196527  0.08980747]\n",
      " [ 0.08546634  0.04109031 -0.26206594  0.1262147 ]\n",
      " [ 0.09157643  0.03972642 -0.2620419   0.16099433]\n",
      " [ 0.09937904  0.03812957 -0.26184225  0.19426466]\n",
      " [ 0.10880277  0.03627389 -0.26144542  0.22614747]\n",
      " [ 0.11978115  0.03413565 -0.260855    0.2567673 ]\n",
      " [ 0.13225295  0.03169268 -0.26009623  0.28625074]\n",
      " [ 0.14616229  0.02892371 -0.2592132   0.3147258 ]\n",
      " [ 0.16145868  0.02580763 -0.25826661  0.3423213 ]\n",
      " [ 0.17809704  0.02232277 -0.25733216  0.36916628]\n",
      " [ 0.19603752  0.018446   -0.25649951  0.39538949]\n",
      " [ 0.2152453   0.0141519  -0.25587177  0.42111887]\n",
      " [ 0.2356903   0.00941181 -0.25556566  0.44648104]\n",
      " [ 0.25734669  0.0041928  -0.25571212  0.47160084]\n",
      " [ 0.28019233 -0.0015434  -0.2564576   0.49660084]\n",
      " [ 0.30420797 -0.00784168 -0.25796589  0.52160084]]\n"
     ]
    }
   ],
   "source": [
    "# casadi mpc with exact penalty\n",
    "test_q = np.array([ 0.,  6.,  1.,  0., 0., 0., 0., 0., 1., 2.])\n",
    "test_p = np.array([ -2.,  0.,  0.,  0., 100., 100., 100., 100., -1,  0.])\n",
    "\n",
    "control = casadi_control.CasadiControl(track_coord)\n",
    "\n",
    "x0 = (sample_xinit(1)).numpy()\n",
    "print(x0[0])\n",
    "dc = 4 #number constraints\n",
    "df = 2 #number of states we do not really need with casadi, like simga_0 and sigma_diff\n",
    "dx = n_state #number states\n",
    "du = n_ctrl #number control inputs\n",
    "horizon = mpc_T\n",
    "sol = control.mpc_casadi(test_q,test_p,x0,horizon,df,dc,dx,du,track_width,v_max)\n",
    "N = horizon\n",
    "u = sol[-du*N:]\n",
    "x = sol[:-du*N]\n",
    "u_r = u.reshape(N,du)\n",
    "x_r = x.reshape(N+1,dx-df-dc)\n",
    "print(u_r)\n",
    "print(x_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curv start\n",
      "curv end\n",
      "curv start\n",
      "curv end\n",
      "curv start\n",
      "curv end\n",
      "This is Ipopt version 3.14.11, running with linear solver MUMPS 5.4.1.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:      304\n",
      "Number of nonzeros in inequality constraint Jacobian.:       62\n",
      "Number of nonzeros in Lagrangian Hessian.............:      225\n",
      "\n",
      "Total number of variables............................:       94\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:       64\n",
      "Total number of inequality constraints...............:       62\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:       62\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  2.4337430e+00 2.62e-01 5.72e-01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1 -1.1855859e+00 1.92e-03 4.31e+00  -1.0 2.63e-01    -  1.64e-01 1.00e+00f  1\n",
      "   2 -4.4645170e+00 5.83e-04 2.27e-01  -1.0 4.18e-01    -  8.23e-01 1.00e+00f  1\n",
      "   3 -4.8152742e+00 1.19e-04 9.28e-02  -1.7 1.62e-01    -  8.71e-01 1.00e+00f  1\n",
      "   4 -4.8237876e+00 2.14e-06 2.72e-05  -2.5 1.97e-02    -  1.00e+00 1.00e+00h  1\n",
      "   5 -4.8238634e+00 1.30e-09 1.95e-08  -3.8 1.33e-03    -  1.00e+00 1.00e+00h  1\n",
      "   6 -4.8238634e+00 1.07e-11 1.58e-10  -5.7 1.36e-04    -  1.00e+00 1.00e+00h  1\n",
      "   7 -4.8238634e+00 1.65e-15 2.45e-14  -8.6 1.66e-06    -  1.00e+00 1.00e+00h  1\n",
      "\n",
      "Number of Iterations....: 7\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:  -4.8238634121055579e+00   -4.8238634121055579e+00\n",
      "Dual infeasibility......:   2.4535928844215960e-14    2.4535928844215960e-14\n",
      "Constraint violation....:   1.6521072704334117e-15    1.6521072704334117e-15\n",
      "Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   2.5079779080701763e-09    2.5079779080701763e-09\n",
      "Overall NLP error.......:   2.5079779080701763e-09    2.5079779080701763e-09\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 8\n",
      "Number of objective gradient evaluations             = 8\n",
      "Number of equality constraint evaluations            = 8\n",
      "Number of inequality constraint evaluations          = 8\n",
      "Number of equality constraint Jacobian evaluations   = 8\n",
      "Number of inequality constraint Jacobian evaluations = 8\n",
      "Number of Lagrangian Hessian evaluations             = 7\n",
      "Total seconds in IPOPT                               = 0.006\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "       nlp_f  |  13.00us (  1.63us)  10.50us (  1.31us)         8\n",
      "       nlp_g  | 181.00us ( 22.62us) 174.62us ( 21.83us)         8\n",
      "  nlp_grad_f  |  13.00us (  1.44us)  15.31us (  1.70us)         9\n",
      "  nlp_hess_l  | 657.00us ( 93.86us) 657.60us ( 93.94us)         7\n",
      "   nlp_jac_g  | 282.00us ( 31.33us) 282.52us ( 31.39us)         9\n",
      "       total  |   6.16ms (  6.16ms)   6.15ms (  6.15ms)         1\n",
      "[[7.28144490e-01 1.41376385e-04]\n",
      " [6.95592718e-01 1.08427495e-02]\n",
      " [6.65406610e-01 1.95362921e-02]\n",
      " [6.37656196e-01 2.63431542e-02]\n",
      " [6.12396541e-01 3.13706789e-02]\n",
      " [5.89668821e-01 3.47147509e-02]\n",
      " [5.69501258e-01 3.64610829e-02]\n",
      " [5.51909953e-01 3.66857832e-02]\n",
      " [5.36899622e-01 3.54554644e-02]\n",
      " [5.24464233e-01 3.28270891e-02]\n",
      " [5.14587524e-01 2.88476989e-02]\n",
      " [5.07243375e-01 2.35541318e-02]\n",
      " [5.02396012e-01 1.69728045e-02]\n",
      " [5.00000000e-01 9.11961440e-03]\n",
      " [5.00000000e-01 9.78984383e-13]]\n",
      "[[ 0.08112477  0.04224969 -0.26196527  0.08980747]\n",
      " [ 0.08546634  0.04109031 -0.26206594  0.1262147 ]\n",
      " [ 0.09157643  0.03972642 -0.2620419   0.16099433]\n",
      " [ 0.09937904  0.03812957 -0.26184225  0.19426466]\n",
      " [ 0.10880277  0.03627389 -0.26144542  0.22614747]\n",
      " [ 0.11978115  0.03413565 -0.260855    0.2567673 ]\n",
      " [ 0.13225295  0.03169268 -0.26009623  0.28625074]\n",
      " [ 0.14616229  0.02892371 -0.2592132   0.3147258 ]\n",
      " [ 0.16145868  0.02580763 -0.25826661  0.3423213 ]\n",
      " [ 0.17809704  0.02232277 -0.25733216  0.36916628]\n",
      " [ 0.19603752  0.018446   -0.25649951  0.3953895 ]\n",
      " [ 0.21524531  0.0141519  -0.25587177  0.42111887]\n",
      " [ 0.2356903   0.00941181 -0.25556566  0.44648104]\n",
      " [ 0.25734669  0.0041928  -0.25571212  0.47160084]\n",
      " [ 0.28019233 -0.00154341 -0.2564576   0.49660084]\n",
      " [ 0.30420797 -0.00784168 -0.25796589  0.52160084]]\n"
     ]
    }
   ],
   "source": [
    "#casadi mpc with state constraints - NOTE: cost parameter vector has now different dimensions\n",
    "test_q = np.array([ 0.,  6.,  1.,  0., 1., 2.])\n",
    "test_p = np.array([ -2.,  0.,  0.,  0.,  -1,  0.])\n",
    "\n",
    "sol = control.mpc_casadi_with_constraints(test_q,test_p,x0,horizon,df,dc,dx,du,track_width,v_max)\n",
    "N = horizon\n",
    "u = sol[-du*N:]\n",
    "x = sol[:-du*N]\n",
    "u_r = u.reshape(N,du)\n",
    "x_r = x.reshape(N+1,dx-df-dc)\n",
    "print(u_r)\n",
    "print(x_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each mpc returns a prediction of the states and the inputs over the horizon for all batches and all dimensions,\n",
    "# they are stored in the following order pred_x = [horizon,batch, dimension].\n",
    "# To penalize a control behaviour that does not enforce enough progress within a horizon we can try to chose \n",
    "# our loss as -pred_x[mpc_T-1,:,0]\n",
    "\n",
    "def get_loss_progress(x_init, dx, _Q, _p, mpc_T=mpc_T):    \n",
    "        \n",
    "        pred_x, pred_u, pred_objs = mpc.MPC(\n",
    "            dx.n_state, dx.n_ctrl, mpc_T,\n",
    "            u_lower=u_lower, u_upper=u_upper, u_init=u_init,\n",
    "            lqr_iter=lqr_iter,\n",
    "            verbose=0,\n",
    "            exit_unconverged=False,\n",
    "            detach_unconverged=True,\n",
    "            linesearch_decay=dx.linesearch_decay,\n",
    "            max_linesearch_iter=dx.max_linesearch_iter,\n",
    "            grad_method=grad_method,\n",
    "            eps=5,\n",
    "            n_batch=n_batch,\n",
    "        )(x_init, QuadCost(_Q, _p), dx)\n",
    "        \n",
    "        #I added the second term to account the initial state (to kind of normalize the progress)\n",
    "        progress_loss = torch.mean(-pred_x[mpc_T-1,:,0] + pred_x[0,:,0])\n",
    "        \n",
    "        #penalty_loss = pred_x[]\n",
    "            \n",
    "        return progress_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = []\n",
    "learn_q_logit_state = torch.ones(n_state-7, requires_grad=True).to(device)\n",
    "learn_q_logit_sigma_diff = torch.ones(1, requires_grad=True).to(device)\n",
    "learn_q_logit_input = torch.ones(n_ctrl, requires_grad=True).to(device)\n",
    "learn_p_state = torch.zeros(n_state-7, requires_grad=True).to(device)\n",
    "learn_p_sigma_diff = torch.zeros(1, requires_grad=True).to(device)\n",
    "learn_p_input = torch.zeros(n_ctrl, requires_grad=True).to(device)\n",
    "params1 += [learn_q_logit_state, learn_q_logit_sigma_diff, learn_q_logit_input, learn_p_state, learn_p_sigma_diff, learn_p_input]\n",
    "env_params = true_dx.params\n",
    "q_penalty = .00*torch.ones(4).to(device)\n",
    "p_penalty = 10.0*torch.ones(4).to(device)\n",
    "q_sigma = .00*torch.ones(1).to(device)\n",
    "p_sigma = .00*torch.ones(1).to(device)\n",
    "q_sigma_0 = .00*torch.ones(1).to(device)\n",
    "p_sigma_0 = .00*torch.ones(1).to(device)\n",
    "track_coord = track_coord.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn_q_logit = torch.ones_like(true_q, requires_grad=True).to(device)\n",
    "#learn_p = torch.zeros_like(true_p, requires_grad=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "params = [{\n",
    "            'params': params1,\n",
    "            'lr': 2e-3,\n",
    "            'alpha': 0.99,\n",
    "            }]\n",
    "dx = true_dx.__class__(track_coord,env_params)\n",
    "\n",
    "opt = optim.RMSprop(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1.],\n",
      "       grad_fn=<CatBackward0>)\n",
      "Batch: 0  Progression with MPC_T= 15 :  0.0995\n",
      "tensor([0.0000, 1.0200, 1.0200, 0.9800, 0.0000, 0.9800, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9800, 0.9800], grad_fn=<CatBackward0>)\n",
      "Batch: 1  Progression with MPC_T= 15 :  0.106\n",
      "tensor([0.0000, 1.0050, 1.0341, 0.9647, 0.0000, 0.9660, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9620, 0.9697], grad_fn=<CatBackward0>)\n",
      "Batch: 2  Progression with MPC_T= 15 :  0.1239\n",
      "tensor([0.0000, 0.9994, 1.0452, 0.9515, 0.0000, 0.9518, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9492, 0.9591], grad_fn=<CatBackward0>)\n",
      "Batch: 3  Progression with MPC_T= 15 :  0.082\n",
      "tensor([0.0000, 1.0013, 1.0480, 0.9441, 0.0000, 0.9431, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9444, 0.9531], grad_fn=<CatBackward0>)\n",
      "Batch: 4  Progression with MPC_T= 15 :  0.078\n",
      "tensor([0.0000, 0.9977, 1.0615, 0.9371, 0.0000, 0.9347, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9396, 0.9507], grad_fn=<CatBackward0>)\n",
      "Batch: 5  Progression with MPC_T= 15 :  0.0895\n",
      "tensor([0.0000, 0.9783, 1.0693, 0.9295, 0.0000, 0.9244, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9328, 0.9543], grad_fn=<CatBackward0>)\n",
      "Batch: 6  Progression with MPC_T= 15 :  0.1306\n",
      "tensor([0.0000, 0.9750, 1.0738, 0.9193, 0.0000, 0.9145, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9215, 0.9454], grad_fn=<CatBackward0>)\n",
      "Batch: 7  Progression with MPC_T= 15 :  0.0848\n",
      "tensor([0.0000, 0.9749, 1.0841, 0.9131, 0.0000, 0.9087, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9160, 0.9366], grad_fn=<CatBackward0>)\n",
      "Batch: 8  Progression with MPC_T= 15 :  0.1382\n",
      "tensor([0.0000, 0.9718, 1.0902, 0.9037, 0.0000, 0.8987, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9068, 0.9364], grad_fn=<CatBackward0>)\n",
      "Batch: 9  Progression with MPC_T= 15 :  0.1138\n",
      "tensor([0.0000, 0.9720, 1.0983, 0.8968, 0.0000, 0.8906, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9010, 0.9291], grad_fn=<CatBackward0>)\n",
      "Batch: 10  Progression with MPC_T= 15 :  0.1316\n",
      "tensor([0.0000, 0.9637, 1.1001, 0.8890, 0.0000, 0.8829, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8914, 0.9242], grad_fn=<CatBackward0>)\n",
      "Batch: 11  Progression with MPC_T= 15 :  0.1201\n",
      "tensor([0.0000, 0.9610, 1.1027, 0.8827, 0.0000, 0.8766, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8867, 0.9131], grad_fn=<CatBackward0>)\n",
      "Batch: 12  Progression with MPC_T= 15 :  0.1571\n",
      "tensor([0.0000, 0.9420, 1.1115, 0.8749, 0.0000, 0.8660, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8781, 0.9090], grad_fn=<CatBackward0>)\n",
      "Batch: 13  Progression with MPC_T= 15 :  0.0943\n",
      "tensor([0.0000, 0.9455, 1.1203, 0.8698, 0.0000, 0.8619, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8729, 0.8975], grad_fn=<CatBackward0>)\n",
      "Batch: 14  Progression with MPC_T= 15 :  0.1592\n",
      "tensor([0.0000, 0.9392, 1.1246, 0.8624, 0.0000, 0.8534, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8647, 0.8920], grad_fn=<CatBackward0>)\n",
      "Batch: 15  Progression with MPC_T= 15 :  0.1555\n",
      "tensor([0.0000, 0.9381, 1.1272, 0.8553, 0.0000, 0.8469, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8565, 0.8876], grad_fn=<CatBackward0>)\n",
      "Batch: 16  Progression with MPC_T= 15 :  0.1619\n",
      "tensor([0.0000, 0.9383, 1.1334, 0.8481, 0.0000, 0.8404, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8496, 0.8810], grad_fn=<CatBackward0>)\n",
      "Batch: 17  Progression with MPC_T= 15 :  0.0883\n",
      "tensor([0.0000, 0.9383, 1.1354, 0.8445, 0.0000, 0.8366, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8464, 0.8740], grad_fn=<CatBackward0>)\n",
      "Batch: 18  Progression with MPC_T= 15 :  0.094\n",
      "tensor([0.0000, 0.9420, 1.1411, 0.8403, 0.0000, 0.8329, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8425, 0.8689], grad_fn=<CatBackward0>)\n",
      "Batch: 19  Progression with MPC_T= 15 :  0.1739\n",
      "tensor([0.0000, 0.9306, 1.1427, 0.8339, 0.0000, 0.8254, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8350, 0.8644], grad_fn=<CatBackward0>)\n",
      "Batch: 20  Progression with MPC_T= 15 :  0.1024\n",
      "tensor([0.0000, 0.9306, 1.1473, 0.8298, 0.0000, 0.8214, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8307, 0.8563], grad_fn=<CatBackward0>)\n",
      "Batch: 21  Progression with MPC_T= 15 :  0.111\n",
      "tensor([0.0000, 0.9316, 1.1543, 0.8252, 0.0000, 0.8174, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8265, 0.8478], grad_fn=<CatBackward0>)\n",
      "Batch: 22  Progression with MPC_T= 15 :  0.1046\n",
      "tensor([0.0000, 0.9273, 1.1594, 0.8211, 0.0000, 0.8133, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8220, 0.8412], grad_fn=<CatBackward0>)\n",
      "Batch: 23  Progression with MPC_T= 15 :  0.2051\n",
      "tensor([0.0000, 0.9186, 1.1620, 0.8135, 0.0000, 0.8042, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8132, 0.8363], grad_fn=<CatBackward0>)\n",
      "Batch: 24  Progression with MPC_T= 15 :  0.1677\n",
      "tensor([0.0000, 0.9221, 1.1674, 0.8072, 0.0000, 0.7989, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8064, 0.8341], grad_fn=<CatBackward0>)\n",
      "Batch: 25  Progression with MPC_T= 15 :  0.1577\n",
      "tensor([0.0000, 0.9159, 1.1748, 0.8016, 0.0000, 0.7932, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.8013, 0.8226], grad_fn=<CatBackward0>)\n",
      "Batch: 26  Progression with MPC_T= 15 :  0.1431\n",
      "tensor([0.0000, 0.9088, 1.1807, 0.7965, 0.0000, 0.7876, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7963, 0.8183], grad_fn=<CatBackward0>)\n",
      "Batch: 27  Progression with MPC_T= 15 :  0.117\n",
      "tensor([0.0000, 0.9089, 1.1818, 0.7925, 0.0000, 0.7838, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7922, 0.8153], grad_fn=<CatBackward0>)\n",
      "Batch: 28  Progression with MPC_T= 15 :  0.169\n",
      "tensor([0.0000, 0.9097, 1.1879, 0.7869, 0.0000, 0.7789, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7864, 0.8105], grad_fn=<CatBackward0>)\n",
      "Batch: 29  Progression with MPC_T= 15 :  0.1295\n",
      "tensor([0.0000, 0.9094, 1.1877, 0.7828, 0.0000, 0.7750, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7830, 0.8040], grad_fn=<CatBackward0>)\n",
      "Batch: 30  Progression with MPC_T= 15 :  0.1516\n",
      "tensor([0.0000, 0.9093, 1.1894, 0.7779, 0.0000, 0.7702, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7787, 0.8034], grad_fn=<CatBackward0>)\n",
      "Batch: 31  Progression with MPC_T= 15 :  0.1313\n",
      "tensor([0.0000, 0.9088, 1.1947, 0.7736, 0.0000, 0.7667, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7747, 0.7981], grad_fn=<CatBackward0>)\n",
      "Batch: 32  Progression with MPC_T= 15 :  0.1305\n",
      "tensor([0.0000, 0.9101, 1.2010, 0.7694, 0.0000, 0.7629, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7702, 0.7914], grad_fn=<CatBackward0>)\n",
      "Batch: 33  Progression with MPC_T= 15 :  0.1281\n",
      "tensor([0.0000, 0.9093, 1.2045, 0.7653, 0.0000, 0.7593, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7661, 0.7889], grad_fn=<CatBackward0>)\n",
      "Batch: 34  Progression with MPC_T= 15 :  0.1459\n",
      "tensor([0.0000, 0.9021, 1.2065, 0.7613, 0.0000, 0.7546, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7620, 0.7818], grad_fn=<CatBackward0>)\n",
      "Batch: 35  Progression with MPC_T= 15 :  0.1437\n",
      "tensor([0.0000, 0.9022, 1.2064, 0.7571, 0.0000, 0.7507, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7578, 0.7764], grad_fn=<CatBackward0>)\n",
      "Batch: 36  Progression with MPC_T= 15 :  0.1416\n",
      "tensor([0.0000, 0.8966, 1.2080, 0.7531, 0.0000, 0.7464, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7533, 0.7714], grad_fn=<CatBackward0>)\n",
      "Batch: 37  Progression with MPC_T= 15 :  0.1707\n",
      "tensor([0.0000, 0.8888, 1.2103, 0.7484, 0.0000, 0.7404, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7485, 0.7684], grad_fn=<CatBackward0>)\n",
      "Batch: 38  Progression with MPC_T= 15 :  0.0997\n",
      "tensor([0.0000, 0.8900, 1.2158, 0.7452, 0.0000, 0.7383, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7444, 0.7642], grad_fn=<CatBackward0>)\n",
      "Batch: 39  Progression with MPC_T= 15 :  0.1501\n",
      "tensor([0.0000, 0.8899, 1.2191, 0.7406, 0.0000, 0.7340, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7391, 0.7604], grad_fn=<CatBackward0>)\n",
      "Batch: 40  Progression with MPC_T= 15 :  0.196\n",
      "tensor([0.0000, 0.8849, 1.2248, 0.7354, 0.0000, 0.7280, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7335, 0.7560], grad_fn=<CatBackward0>)\n",
      "Batch: 41  Progression with MPC_T= 15 :  0.1654\n",
      "tensor([0.0000, 0.8788, 1.2258, 0.7311, 0.0000, 0.7231, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7292, 0.7512], grad_fn=<CatBackward0>)\n",
      "Batch: 42  Progression with MPC_T= 15 :  0.2285\n",
      "tensor([0.0000, 0.8746, 1.2295, 0.7250, 0.0000, 0.7161, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7223, 0.7448], grad_fn=<CatBackward0>)\n",
      "Batch: 43  Progression with MPC_T= 15 :  0.1389\n",
      "tensor([0.0000, 0.8749, 1.2356, 0.7212, 0.0000, 0.7126, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7175, 0.7380], grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 44  Progression with MPC_T= 15 :  0.1555\n",
      "tensor([0.0000, 0.8753, 1.2421, 0.7170, 0.0000, 0.7090, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7134, 0.7298], grad_fn=<CatBackward0>)\n",
      "Batch: 45  Progression with MPC_T= 15 :  0.1923\n",
      "tensor([0.0000, 0.8687, 1.2470, 0.7122, 0.0000, 0.7033, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7085, 0.7249], grad_fn=<CatBackward0>)\n",
      "Batch: 46  Progression with MPC_T= 15 :  0.1386\n",
      "tensor([0.0000, 0.8701, 1.2496, 0.7085, 0.0000, 0.7004, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7042, 0.7176], grad_fn=<CatBackward0>)\n",
      "Batch: 47  Progression with MPC_T= 15 :  0.149\n",
      "tensor([0.0000, 0.8677, 1.2527, 0.7049, 0.0000, 0.6964, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.7001, 0.7112], grad_fn=<CatBackward0>)\n",
      "Batch: 48  Progression with MPC_T= 15 :  0.1475\n",
      "tensor([0.0000, 0.8699, 1.2588, 0.7010, 0.0000, 0.6934, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6962, 0.7043], grad_fn=<CatBackward0>)\n",
      "Batch: 49  Progression with MPC_T= 15 :  0.1431\n",
      "tensor([0.0000, 0.8655, 1.2609, 0.6976, 0.0000, 0.6895, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6926, 0.6953], grad_fn=<CatBackward0>)\n",
      "Batch: 50  Progression with MPC_T= 15 :  0.1839\n",
      "tensor([0.0000, 0.8654, 1.2658, 0.6932, 0.0000, 0.6851, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6881, 0.6859], grad_fn=<CatBackward0>)\n",
      "Batch: 51  Progression with MPC_T= 15 :  0.1723\n",
      "tensor([0.0000, 0.8633, 1.2720, 0.6888, 0.0000, 0.6811, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6838, 0.6772], grad_fn=<CatBackward0>)\n",
      "Batch: 52  Progression with MPC_T= 15 :  0.1831\n",
      "tensor([0.0000, 0.8643, 1.2779, 0.6842, 0.0000, 0.6771, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6792, 0.6744], grad_fn=<CatBackward0>)\n",
      "Batch: 53  Progression with MPC_T= 15 :  0.195\n",
      "tensor([0.0000, 0.8654, 1.2843, 0.6795, 0.0000, 0.6725, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6744, 0.6688], grad_fn=<CatBackward0>)\n",
      "Batch: 54  Progression with MPC_T= 15 :  0.174\n",
      "tensor([0.0000, 0.8632, 1.2841, 0.6752, 0.0000, 0.6685, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6699, 0.6667], grad_fn=<CatBackward0>)\n",
      "Batch: 55  Progression with MPC_T= 15 :  0.1596\n",
      "tensor([0.0000, 0.8563, 1.2879, 0.6715, 0.0000, 0.6644, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6659, 0.6565], grad_fn=<CatBackward0>)\n",
      "Batch: 56  Progression with MPC_T= 15 :  0.1939\n",
      "tensor([0.0000, 0.8489, 1.2891, 0.6668, 0.0000, 0.6590, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6608, 0.6526], grad_fn=<CatBackward0>)\n",
      "Batch: 57  Progression with MPC_T= 15 :  0.1905\n",
      "tensor([0.0000, 0.8483, 1.2931, 0.6624, 0.0000, 0.6551, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6558, 0.6498], grad_fn=<CatBackward0>)\n",
      "Batch: 58  Progression with MPC_T= 15 :  0.2114\n",
      "tensor([0.0000, 0.8422, 1.2961, 0.6575, 0.0000, 0.6498, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6509, 0.6477], grad_fn=<CatBackward0>)\n",
      "Batch: 59  Progression with MPC_T= 15 :  0.2146\n",
      "tensor([0.0000, 0.8326, 1.2944, 0.6536, 0.0000, 0.6440, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6466, 0.6397], grad_fn=<CatBackward0>)\n",
      "Batch: 60  Progression with MPC_T= 15 :  0.2024\n",
      "tensor([0.0000, 0.8312, 1.2956, 0.6492, 0.0000, 0.6399, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6418, 0.6341], grad_fn=<CatBackward0>)\n",
      "Batch: 61  Progression with MPC_T= 15 :  0.2171\n",
      "tensor([0.0000, 0.8237, 1.2955, 0.6448, 0.0000, 0.6345, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6367, 0.6297], grad_fn=<CatBackward0>)\n",
      "Batch: 62  Progression with MPC_T= 15 :  0.2435\n",
      "tensor([0.0000, 0.8174, 1.2942, 0.6400, 0.0000, 0.6285, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6314, 0.6250], grad_fn=<CatBackward0>)\n",
      "Batch: 63  Progression with MPC_T= 15 :  0.2351\n",
      "tensor([0.0000, 0.8113, 1.2938, 0.6357, 0.0000, 0.6224, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6266, 0.6209], grad_fn=<CatBackward0>)\n",
      "Batch: 64  Progression with MPC_T= 15 :  0.1791\n",
      "tensor([0.0000, 0.8113, 1.3001, 0.6319, 0.0000, 0.6191, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6223, 0.6164], grad_fn=<CatBackward0>)\n",
      "Batch: 65  Progression with MPC_T= 15 :  0.1888\n",
      "tensor([0.0000, 0.8138, 1.3049, 0.6281, 0.0000, 0.6158, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6183, 0.6119], grad_fn=<CatBackward0>)\n",
      "Batch: 66  Progression with MPC_T= 15 :  0.2372\n",
      "tensor([0.0000, 0.8114, 1.3059, 0.6233, 0.0000, 0.6109, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6128, 0.6114], grad_fn=<CatBackward0>)\n",
      "Batch: 67  Progression with MPC_T= 15 :  0.2038\n",
      "tensor([0.0000, 0.8135, 1.3094, 0.6191, 0.0000, 0.6072, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6081, 0.6097], grad_fn=<CatBackward0>)\n",
      "Batch: 68  Progression with MPC_T= 15 :  0.193\n",
      "tensor([0.0000, 0.8112, 1.3115, 0.6153, 0.0000, 0.6035, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.6033, 0.6069], grad_fn=<CatBackward0>)\n",
      "Batch: 69  Progression with MPC_T= 15 :  0.2462\n",
      "tensor([0.0000, 0.8124, 1.3147, 0.6104, 0.0000, 0.5992, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5980, 0.6064], grad_fn=<CatBackward0>)\n",
      "Batch: 70  Progression with MPC_T= 15 :  0.1873\n",
      "tensor([0.0000, 0.8146, 1.3201, 0.6065, 0.0000, 0.5963, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5937, 0.6048], grad_fn=<CatBackward0>)\n",
      "Batch: 71  Progression with MPC_T= 15 :  0.2252\n",
      "tensor([0.0000, 0.8082, 1.3216, 0.6020, 0.0000, 0.5918, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5883, 0.6015], grad_fn=<CatBackward0>)\n",
      "Batch: 72  Progression with MPC_T= 15 :  0.2192\n",
      "tensor([0.0000, 0.8090, 1.3268, 0.5974, 0.0000, 0.5885, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5833, 0.6007], grad_fn=<CatBackward0>)\n",
      "Batch: 73  Progression with MPC_T= 15 :  0.2458\n",
      "tensor([0.0000, 0.8045, 1.3313, 0.5929, 0.0000, 0.5833, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5788, 0.5945], grad_fn=<CatBackward0>)\n",
      "Batch: 74  Progression with MPC_T= 15 :  0.2889\n",
      "tensor([0.0000, 0.7983, 1.3323, 0.5877, 0.0000, 0.5771, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5734, 0.5946], grad_fn=<CatBackward0>)\n",
      "Batch: 75  Progression with MPC_T= 15 :  0.2802\n",
      "tensor([0.0000, 0.7922, 1.3359, 0.5826, 0.0000, 0.5712, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5679, 0.5896], grad_fn=<CatBackward0>)\n",
      "Batch: 76  Progression with MPC_T= 15 :  0.253\n",
      "tensor([0.0000, 0.7891, 1.3385, 0.5781, 0.0000, 0.5664, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5629, 0.5885], grad_fn=<CatBackward0>)\n",
      "Batch: 77  Progression with MPC_T= 15 :  0.3313\n",
      "tensor([0.0000, 0.7839, 1.3395, 0.5727, 0.0000, 0.5591, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5572, 0.5872], grad_fn=<CatBackward0>)\n",
      "Batch: 78  Progression with MPC_T= 15 :  0.297\n",
      "tensor([0.0000, 0.7838, 1.3408, 0.5678, 0.0000, 0.5537, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5519, 0.5889], grad_fn=<CatBackward0>)\n",
      "Batch: 79  Progression with MPC_T= 15 :  0.2697\n",
      "tensor([0.0000, 0.7811, 1.3430, 0.5637, 0.0000, 0.5485, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5477, 0.5890], grad_fn=<CatBackward0>)\n",
      "Batch: 80  Progression with MPC_T= 15 :  0.2115\n",
      "tensor([0.0000, 0.7796, 1.3458, 0.5600, 0.0000, 0.5448, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5437, 0.5871], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 81  Progression with MPC_T= 15 :  0.264\n",
      "tensor([0.0000, 0.7772, 1.3474, 0.5570, 0.0000, 0.5402, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5406, 0.5846], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 82  Progression with MPC_T= 15 :  0.2821\n",
      "tensor([0.0000, 0.7768, 1.3502, 0.5529, 0.0000, 0.5366, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5361, 0.5833], grad_fn=<CatBackward0>)\n",
      "Batch: 83  Progression with MPC_T= 15 :  0.2666\n",
      "tensor([0.0000, 0.7771, 1.3531, 0.5481, 0.0000, 0.5332, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5312, 0.5834], grad_fn=<CatBackward0>)\n",
      "Batch: 84  Progression with MPC_T= 15 :  0.3003\n",
      "tensor([0.0000, 0.7767, 1.3563, 0.5439, 0.0000, 0.5277, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5265, 0.5767], grad_fn=<CatBackward0>)\n",
      "Batch: 85  Progression with MPC_T= 15 :  0.2842\n",
      "tensor([0.0000, 0.7796, 1.3590, 0.5392, 0.0000, 0.5235, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5217, 0.5758], grad_fn=<CatBackward0>)\n",
      "Batch: 86  Progression with MPC_T= 15 :  0.267\n",
      "tensor([0.0000, 0.7850, 1.3607, 0.5349, 0.0000, 0.5199, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5172, 0.5736], grad_fn=<CatBackward0>)\n",
      "Batch: 87  Progression with MPC_T= 15 :  0.2756\n",
      "tensor([0.0000, 0.7789, 1.3656, 0.5304, 0.0000, 0.5150, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5122, 0.5686], grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 88  Progression with MPC_T= 15 :  0.2973\n",
      "tensor([0.0000, 0.7750, 1.3689, 0.5270, 0.0000, 0.5095, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5084, 0.5629], grad_fn=<CatBackward0>)\n",
      "Batch: 89  Progression with MPC_T= 15 :  0.2898\n",
      "tensor([0.0000, 0.7769, 1.3740, 0.5223, 0.0000, 0.5061, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5032, 0.5627], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 90  Progression with MPC_T= 15 :  0.3366\n",
      "tensor([0.0000, 0.7789, 1.3756, 0.5180, 0.0000, 0.5018, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4984, 0.5612], grad_fn=<CatBackward0>)\n",
      "Batch: 91  Progression with MPC_T= 15 :  0.3679\n",
      "tensor([0.0000, 0.7688, 1.3767, 0.5131, 0.0000, 0.4946, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4931, 0.5536], grad_fn=<CatBackward0>)\n",
      "Batch: 92  Progression with MPC_T= 15 :  0.3099\n",
      "tensor([0.0000, 0.7713, 1.3811, 0.5086, 0.0000, 0.4905, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4882, 0.5498], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 93  Progression with MPC_T= 15 :  0.2842\n",
      "tensor([0.0000, 0.7790, 1.3828, 0.5056, 0.0000, 0.4877, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4850, 0.5519], grad_fn=<CatBackward0>)\n",
      "Batch: 94  Progression with MPC_T= 15 :  0.3336\n",
      "tensor([0.0000, 0.7766, 1.3843, 0.5016, 0.0000, 0.4829, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4807, 0.5499], grad_fn=<CatBackward0>)\n",
      "Batch: 95  Progression with MPC_T= 15 :  0.315\n",
      "tensor([0.0000, 0.7768, 1.3886, 0.4968, 0.0000, 0.4784, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4758, 0.5487], grad_fn=<CatBackward0>)\n",
      "Batch: 96  Progression with MPC_T= 15 :  0.3157\n",
      "tensor([0.0000, 0.7710, 1.3935, 0.4931, 0.0000, 0.4735, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4718, 0.5420], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 97  Progression with MPC_T= 15 :  0.3844\n",
      "tensor([0.0000, 0.7722, 1.3931, 0.4888, 0.0000, 0.4682, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4673, 0.5411], grad_fn=<CatBackward0>)\n",
      "Batch: 98  Progression with MPC_T= 15 :  0.3603\n",
      "tensor([0.0000, 0.7709, 1.3958, 0.4844, 0.0000, 0.4639, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4628, 0.5403], grad_fn=<CatBackward0>)\n",
      "Batch: 99  Progression with MPC_T= 15 :  0.2921\n",
      "tensor([0.0000, 0.7740, 1.3990, 0.4799, 0.0000, 0.4602, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4582, 0.5395], grad_fn=<CatBackward0>)\n",
      "Batch: 100  Progression with MPC_T= 15 :  0.3837\n",
      "tensor([0.0000, 0.7683, 1.4015, 0.4762, 0.0000, 0.4526, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4546, 0.5330], grad_fn=<CatBackward0>)\n",
      "Batch: 101  Progression with MPC_T= 15 :  0.3667\n",
      "tensor([0.0000, 0.7676, 1.4050, 0.4723, 0.0000, 0.4484, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4504, 0.5326], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 102  Progression with MPC_T= 15 :  0.3149\n",
      "tensor([0.0000, 0.7659, 1.4083, 0.4689, 0.0000, 0.4461, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4468, 0.5322], grad_fn=<CatBackward0>)\n",
      "Batch: 103  Progression with MPC_T= 15 :  0.3321\n",
      "tensor([0.0000, 0.7649, 1.4126, 0.4645, 0.0000, 0.4415, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4422, 0.5297], grad_fn=<CatBackward0>)\n",
      "Batch: 104  Progression with MPC_T= 15 :  0.3382\n",
      "tensor([0.0000, 0.7673, 1.4161, 0.4605, 0.0000, 0.4388, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4378, 0.5302], grad_fn=<CatBackward0>)\n",
      "Batch: 105  Progression with MPC_T= 15 :  0.3275\n",
      "tensor([0.0000, 0.7661, 1.4225, 0.4568, 0.0000, 0.4344, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4337, 0.5280], grad_fn=<CatBackward0>)\n",
      "Batch: 106  Progression with MPC_T= 15 :  0.423\n",
      "tensor([0.0000, 0.7662, 1.4244, 0.4523, 0.0000, 0.4281, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4292, 0.5252], grad_fn=<CatBackward0>)\n",
      "Batch: 107  Progression with MPC_T= 15 :  0.3266\n",
      "tensor([0.0000, 0.7629, 1.4275, 0.4492, 0.0000, 0.4242, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4260, 0.5231], grad_fn=<CatBackward0>)\n",
      "Batch: 108  Progression with MPC_T= 15 :  0.3469\n",
      "tensor([0.0000, 0.7718, 1.4326, 0.4451, 0.0000, 0.4206, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4216, 0.5225], grad_fn=<CatBackward0>)\n",
      "Batch: 109  Progression with MPC_T= 15 :  0.3714\n",
      "tensor([0.0000, 0.7747, 1.4367, 0.4413, 0.0000, 0.4172, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4173, 0.5201], grad_fn=<CatBackward0>)\n",
      "Batch: 110  Progression with MPC_T= 15 :  0.4564\n",
      "tensor([0.0000, 0.7696, 1.4354, 0.4379, 0.0000, 0.4116, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4134, 0.5180], grad_fn=<CatBackward0>)\n",
      "Batch: 111  Progression with MPC_T= 15 :  0.3137\n",
      "tensor([0.0000, 0.7686, 1.4398, 0.4340, 0.0000, 0.4082, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4091, 0.5181], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 112  Progression with MPC_T= 15 :  0.4709\n",
      "tensor([0.0000, 0.7628, 1.4411, 0.4316, 0.0000, 0.4036, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4066, 0.5142], grad_fn=<CatBackward0>)\n",
      "Batch: 113  Progression with MPC_T= 15 :  0.3672\n",
      "tensor([0.0000, 0.7667, 1.4453, 0.4268, 0.0000, 0.4007, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.4014, 0.5154], grad_fn=<CatBackward0>)\n",
      "Batch: 114  Progression with MPC_T= 15 :  0.4282\n",
      "tensor([0.0000, 0.7669, 1.4482, 0.4217, 0.0000, 0.3943, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3962, 0.5109], grad_fn=<CatBackward0>)\n",
      "Batch: 115  Progression with MPC_T= 15 :  0.4268\n",
      "tensor([0.0000, 0.7708, 1.4505, 0.4173, 0.0000, 0.3908, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3916, 0.5134], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 116  Progression with MPC_T= 15 :  0.4669\n",
      "tensor([0.0000, 0.7673, 1.4518, 0.4146, 0.0000, 0.3876, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3886, 0.5128], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 117  Progression with MPC_T= 15 :  0.5425\n",
      "tensor([0.0000, 0.7594, 1.4475, 0.4108, 0.0000, 0.3808, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3846, 0.5118], grad_fn=<CatBackward0>)\n",
      "Batch: 118  Progression with MPC_T= 15 :  0.4502\n",
      "tensor([0.0000, 0.7602, 1.4495, 0.4057, 0.0000, 0.3771, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3794, 0.5125], grad_fn=<CatBackward0>)\n",
      "Batch: 119  Progression with MPC_T= 15 :  0.4366\n",
      "tensor([0.0000, 0.7597, 1.4508, 0.4013, 0.0000, 0.3729, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3748, 0.5123], grad_fn=<CatBackward0>)\n",
      "Batch: 120  Progression with MPC_T= 15 :  0.4216\n",
      "tensor([0.0000, 0.7645, 1.4546, 0.3982, 0.0000, 0.3686, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3714, 0.5113], grad_fn=<CatBackward0>)\n",
      "Batch: 121  Progression with MPC_T= 15 :  0.4426\n",
      "tensor([0.0000, 0.7664, 1.4561, 0.3935, 0.0000, 0.3654, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3665, 0.5136], grad_fn=<CatBackward0>)\n",
      "Batch: 122  Progression with MPC_T= 15 :  0.3696\n",
      "tensor([0.0000, 0.7664, 1.4594, 0.3905, 0.0000, 0.3627, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3633, 0.5104], grad_fn=<CatBackward0>)\n",
      "Batch: 123  Progression with MPC_T= 15 :  0.4792\n",
      "tensor([0.0000, 0.7659, 1.4616, 0.3870, 0.0000, 0.3592, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3595, 0.5091], grad_fn=<CatBackward0>)\n",
      "Batch: 124  Progression with MPC_T= 15 :  0.5207\n",
      "tensor([0.0000, 0.7624, 1.4646, 0.3829, 0.0000, 0.3549, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3553, 0.5049], grad_fn=<CatBackward0>)\n",
      "Batch: 125  Progression with MPC_T= 15 :  0.4462\n",
      "tensor([0.0000, 0.7646, 1.4688, 0.3793, 0.0000, 0.3523, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3516, 0.5057], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 126  Progression with MPC_T= 15 :  0.5285\n",
      "tensor([0.0000, 0.7675, 1.4709, 0.3771, 0.0000, 0.3504, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3490, 0.5035], grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 127  Progression with MPC_T= 15 :  0.4667\n",
      "tensor([0.0000, 0.7651, 1.4756, 0.3740, 0.0000, 0.3472, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3455, 0.4992], grad_fn=<CatBackward0>)\n",
      "Batch: 128  Progression with MPC_T= 15 :  0.5394\n",
      "tensor([0.0000, 0.7570, 1.4743, 0.3708, 0.0000, 0.3422, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3420, 0.4979], grad_fn=<CatBackward0>)\n",
      "Batch: 129  Progression with MPC_T= 15 :  0.5119\n",
      "tensor([0.0000, 0.7521, 1.4730, 0.3669, 0.0000, 0.3373, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3378, 0.4964], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 130  Progression with MPC_T= 15 :  0.5307\n",
      "tensor([0.0000, 0.7482, 1.4733, 0.3639, 0.0000, 0.3326, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3347, 0.4905], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 131  Progression with MPC_T= 15 :  0.4954\n",
      "tensor([0.0000, 0.7520, 1.4760, 0.3620, 0.0000, 0.3311, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3325, 0.4912], grad_fn=<CatBackward0>)\n",
      "Batch: 132  Progression with MPC_T= 15 :  0.4156\n",
      "tensor([0.0000, 0.7534, 1.4795, 0.3594, 0.0000, 0.3280, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3296, 0.4894], grad_fn=<CatBackward0>)\n",
      "Batch: 133  Progression with MPC_T= 15 :  0.4624\n",
      "tensor([0.0000, 0.7503, 1.4804, 0.3549, 0.0000, 0.3233, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3251, 0.4838], grad_fn=<CatBackward0>)\n",
      "Batch: 134  Progression with MPC_T= 15 :  0.51\n",
      "tensor([0.0000, 0.7528, 1.4823, 0.3516, 0.0000, 0.3209, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3214, 0.4865], grad_fn=<CatBackward0>)\n",
      "Batch: 135  Progression with MPC_T= 15 :  0.4899\n",
      "tensor([0.0000, 0.7513, 1.4809, 0.3491, 0.0000, 0.3162, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3187, 0.4844], grad_fn=<CatBackward0>)\n",
      "Batch: 136  Progression with MPC_T= 15 :  0.5323\n",
      "tensor([0.0000, 0.7536, 1.4828, 0.3474, 0.0000, 0.3143, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3166, 0.4831], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 137  Progression with MPC_T= 15 :  0.5272\n",
      "tensor([0.0000, 0.7527, 1.4854, 0.3467, 0.0000, 0.3108, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3156, 0.4769], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 138  Progression with MPC_T= 15 :  0.4889\n",
      "tensor([0.0000, 0.7551, 1.4858, 0.3454, 0.0000, 0.3091, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3139, 0.4790], grad_fn=<CatBackward0>)\n",
      "Batch: 139  Progression with MPC_T= 15 :  0.5089\n",
      "tensor([0.0000, 0.7535, 1.4849, 0.3441, 0.0000, 0.3057, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3125, 0.4793], grad_fn=<CatBackward0>)\n",
      "Batch: 140  Progression with MPC_T= 15 :  0.5175\n",
      "tensor([0.0000, 0.7500, 1.4857, 0.3417, 0.0000, 0.3017, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3096, 0.4764], grad_fn=<CatBackward0>)\n",
      "Batch: 141  Progression with MPC_T= 15 :  0.5402\n",
      "tensor([0.0000, 0.7471, 1.4852, 0.3381, 0.0000, 0.2970, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3059, 0.4742], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 142  Progression with MPC_T= 15 :  0.5002\n",
      "tensor([0.0000, 0.7458, 1.4876, 0.3368, 0.0000, 0.2946, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3044, 0.4716], grad_fn=<CatBackward0>)\n",
      "Batch: 143  Progression with MPC_T= 15 :  0.4293\n",
      "tensor([0.0000, 0.7426, 1.4937, 0.3343, 0.0000, 0.2918, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.3019, 0.4683], grad_fn=<CatBackward0>)\n",
      "Batch: 144  Progression with MPC_T= 15 :  0.5131\n",
      "tensor([0.0000, 0.7425, 1.4913, 0.3322, 0.0000, 0.2880, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.2997, 0.4659], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 145  Progression with MPC_T= 15 :  0.5231\n",
      "tensor([0.0000, 0.7411, 1.4901, 0.3310, 0.0000, 0.2856, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.2982, 0.4664], grad_fn=<CatBackward0>)\n",
      "Batch: 146  Progression with MPC_T= 15 :  0.5332\n",
      "tensor([0.0000, 0.7393, 1.4894, 0.3295, 0.0000, 0.2824, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.2969, 0.4641], grad_fn=<CatBackward0>)\n",
      "Batch: 147  Progression with MPC_T= 15 :  0.5042\n",
      "tensor([0.0000, 0.7352, 1.4918, 0.3277, 0.0000, 0.2778, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.2950, 0.4586], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 148  Progression with MPC_T= 15 :  0.5587\n",
      "tensor([0.0000, 0.7324, 1.4936, 0.3268, 0.0000, 0.2766, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.2939, 0.4578], grad_fn=<CatBackward0>)\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 149  Progression with MPC_T= 15 :  0.4984\n"
     ]
    }
   ],
   "source": [
    "for i in range(150):\n",
    "\n",
    "    q = torch.cat((q_sigma,learn_q_logit_state,q_sigma_0,learn_q_logit_sigma_diff,q_penalty,learn_q_logit_input),dim=0)\n",
    "    p = torch.cat((p_sigma,learn_p_state,p_sigma_0,learn_p_sigma_diff,p_penalty,learn_p_input), dim=0)\n",
    "    #print(q)\n",
    "    print(q)\n",
    "\n",
    "    Q_batch = torch.diag(q).unsqueeze(0).unsqueeze(0).repeat(\n",
    "                mpc_T, n_batch, 1, 1\n",
    "            )\n",
    "    p_batch = p.unsqueeze(0).repeat(mpc_T, n_batch, 1)\n",
    "\n",
    "    x_init = sample_xinit(n_batch).to(device)\n",
    "    #im_loss = get_loss_cost(x_init, dx, Q_batch, p_batch)\n",
    "    im_loss = get_loss_progress(x_init, dx, Q_batch, p_batch)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    im_loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    print('Batch:', i , ' Progression with MPC_T=',mpc_T ,': ', -round(im_loss.item(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can choose the number of samples we want to test (number of initial states)\n",
    "N_test = 1\n",
    "\n",
    "# Whatever I wrote below might be wrong, we have to see if we really can change the mpc_T to Test, \n",
    "# it gives weird results sometimes.\n",
    "# Here we can choose the mpc_T in the test time, which can be much higher than in the training.\n",
    "# Ideally, we would like to have the whole lap here, I guess. But we need to fix the warnings/errors before.\n",
    "mpc_T_test = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init_test = sample_xinit(N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below you can put any initial state you want (any that make sense)\n",
    "#x_init_test = torch.tensor([[1.6, 0.1, -0.8, 0.1,1.6,0,softplus_op(torch.Tensor([-0.1+0.0])), softplus_op(torch.Tensor([-0.1-0.5*track_width])),softplus_op(torch.Tensor([0.1-0.5*track_width])), softplus_op(torch.Tensor([-0.1-0.5*track_width]))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_test = torch.diag(q).unsqueeze(0).unsqueeze(0).repeat(\n",
    "                mpc_T_test, N_test, 1, 1\n",
    "            )\n",
    "p_test = p.unsqueeze(0).repeat(mpc_T_test, N_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_q, true_p = true_dx.get_true_obj()\n",
    "true_q = torch.Tensor([ 0.,  3.,  1.,  0., 0., 0., 1., 2.])\n",
    "true_p = torch.Tensor([ -2.,  0.,  0.,  0., 100., 100.,  -1,  0.])\n",
    "\n",
    "true_q = true_q.to(device)\n",
    "true_p = true_p.to(device)\n",
    "\n",
    "expert_Q = torch.diag(true_q).unsqueeze(0).unsqueeze(0).repeat(\n",
    "            mpc_T_test, N_test, 1, 1\n",
    "        )\n",
    "expert_p = true_p.unsqueeze(0).repeat(mpc_T_test, N_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added here the bounds of U\n",
    "u_lower_test = torch.tensor([-2., -1.]).unsqueeze(0).unsqueeze(0).repeat(mpc_T_test, N_test, 1)\n",
    "u_upper_test = torch.tensor([2., 1.]).unsqueeze(0).unsqueeze(0).repeat(mpc_T_test, N_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mpc_test, u_mpc_test, objs_mpc_test = mpc.MPC(\n",
    "            n_state, n_ctrl, mpc_T_test,\n",
    "            u_lower=u_lower_test, u_upper=u_upper_test, u_init=u_init,\n",
    "            lqr_iter=lqr_iter,\n",
    "            verbose=0,\n",
    "            exit_unconverged=False,\n",
    "            detach_unconverged=True,\n",
    "            linesearch_decay=dx.linesearch_decay,\n",
    "            max_linesearch_iter=dx.max_linesearch_iter,\n",
    "            grad_method=grad_method,\n",
    "            eps=2,\n",
    "            n_batch=N_test,\n",
    "        )(x_init_test, QuadCost(Q_test, p_test), dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frenet_to_cartesian(point_f, ref_path):\n",
    "    \n",
    "    def get_nearest_index(point_f, ref_path):\n",
    "        return ((point_f[0] - ref_path[2,:])**2).argmin()\n",
    "    \n",
    "    def compute_x_coord(point_f, ref_path, nearest_index):\n",
    "        return ref_path[0,nearest_index] - point_f[1]*torch.sin(ref_path[3,nearest_index])\n",
    "    \n",
    "    def compute_y_coord(point_f, ref_path, nearest_index):\n",
    "        return ref_path[1,nearest_index] + point_f[1]*torch.cos(ref_path[3,nearest_index])\n",
    "    \n",
    "    nearest_index = get_nearest_index(point_f, ref_path)\n",
    "    x = compute_x_coord(point_f, ref_path, nearest_index)\n",
    "    y = compute_y_coord(point_f, ref_path, nearest_index)\n",
    "    \n",
    "    return torch.tensor([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "\n",
    "for i in range(mpc_T_test):\n",
    "    xy = frenet_to_cartesian(x_mpc_test[i,0,:2], track_coord)\n",
    "    x_list.append(xy[0].numpy())\n",
    "    y_list.append(xy[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.array(x_list)\n",
    "y_plot = np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 1.], grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_mpc_test.max(0)[0].max(0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_init: 0.15000000000000002\n",
      "y_init: -1.0499999999999994\n",
      "yaw_init: 0.0\n",
      "Total Arc Length: 11.568244517641709\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,5), dpi=120)\n",
    "gen.plotPoints(ax)\n",
    "#gen.pointAtArcLength(0)\n",
    "#gen.writePointsToYaml('../tracks/' + track_name + '.yaml', track_density)\n",
    "\n",
    "ax.scatter(x_plot, y_plot, s=4, color='red')\n",
    "\n",
    "print('x_init: ' + str(gen.xCoords[0]))\n",
    "print('y_init: ' + str(gen.yCoords[0]))\n",
    "print('yaw_init: ' + str(gen.tangentAngle[0]))\n",
    "print('Total Arc Length: ' + str(gen.arcLength[-1]/2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
