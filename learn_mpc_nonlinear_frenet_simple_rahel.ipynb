{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function, Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import parameters_to_vector\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Comment these lines if your MPC is in the current directory.\n",
    "# Otherwise modify to the directory.\n",
    "#import sys\n",
    "#sys.path.append('./../racingDiffMPC/')\n",
    "\n",
    "\n",
    "from mpc import mpc\n",
    "from mpc import casadi_control\n",
    "from mpc.mpc import GradMethods, QuadCost, LinDx\n",
    "#from mpc.dynamics import NNDynamics\n",
    "#import mpc.util as eutil\n",
    "from mpc.env_dx import frenet_kin_bicycle\n",
    "from mpc.track.src import simple_track_generator, track_functions\n",
    "\n",
    "\n",
    "\n",
    "#import sys\n",
    "#from IPython.core import ultratb\n",
    "#sys.excepthook = ultratb.FormattedTB(mode='Verbose',\n",
    "#     color_scheme='Linux', call_pdb=1)\n",
    "\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import pickle as pkl\n",
    "import collections\n",
    "\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to create a track \n",
    "\n",
    "track_density = 300\n",
    "track_width = 0.5\n",
    "gen = simple_track_generator.trackGenerator(track_density,track_width)\n",
    "track_name = 'DEMO_TRACK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.3\n",
    "init = [0,0,0]\n",
    "\n",
    "track_function = {\n",
    "    'DEMO_TRACK'    : track_functions.demo_track,\n",
    "    'HARD_TRACK'    : track_functions.hard_track,\n",
    "    'LONG_TRACK'    : track_functions.long_track,\n",
    "    'LUCERNE_TRACK' : track_functions.lucerne_track,\n",
    "    'BERN_TRACK'    : track_functions.bern_track,\n",
    "    'INFINITY_TRACK': track_functions.infinity_track,\n",
    "    'SNAIL_TRACK'   : track_functions.snail_track\n",
    "}.get(track_name, track_functions.demo_track)\n",
    "    \n",
    "track_function(gen, t, init)\n",
    "    \n",
    "gen.populatePointsAndArcLength()\n",
    "gen.centerTrack()\n",
    "\n",
    "track_coord = torch.from_numpy(np.vstack([gen.xCoords, gen.yCoords, gen.arcLength, gen.tangentAngle, gen.curvature]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "softplus_op = torch.nn.Softplus(10)\n",
    "\n",
    "def sample_xinit(n_batch):\n",
    "    def uniform(shape, low, high):\n",
    "        r = high-low\n",
    "        return torch.rand(shape)*r+low\n",
    "\n",
    "    sigma = uniform(n_batch, 0.01, 2.)\n",
    "    d = uniform(n_batch, -0.1, 0.1)\n",
    "    phi = uniform(n_batch, -0.40*np.pi, 0.40*np.pi)\n",
    "    v = uniform(n_batch, 0., 0.2)\n",
    "    d_lb = softplus_op(-d-0.5*track_width)\n",
    "    d_ub = softplus_op(d-0.5*track_width)\n",
    "    xinit = torch.stack((sigma, d, phi, v, d_lb, d_ub), dim=1)\n",
    "\n",
    "    return xinit\n",
    "\n",
    "true_dx = frenet_kin_bicycle.FrenetKinBicycleDx(track_coord)\n",
    "mpc_T = 15\n",
    "n_batch = 8\n",
    "\n",
    "# Added here the bounds of U\n",
    "u_lower = torch.tensor([-2., -1.]).unsqueeze(0).unsqueeze(0).repeat(mpc_T, n_batch, 1)\n",
    "u_upper = torch.tensor([2., 1.]).unsqueeze(0).unsqueeze(0).repeat(mpc_T, n_batch, 1)\n",
    "\n",
    "n_state = true_dx.n_state\n",
    "n_ctrl = true_dx.n_ctrl\n",
    "\n",
    "u_init=None\n",
    "eps = 1\n",
    "lqr_iter = 500\n",
    "grad_method = GradMethods.AUTO_DIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0877422  -0.09706956  0.9719348   0.05705884  0.01961311  0.00306217]\n",
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.14.11, running with linear solver MUMPS 5.4.1.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:      304\n",
      "Number of nonzeros in inequality constraint Jacobian.:       30\n",
      "Number of nonzeros in Lagrangian Hessian.............:      225\n",
      "\n",
      "Total number of variables............................:       94\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:       64\n",
      "Total number of inequality constraints...............:       30\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:       30\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  0.0000000e+00 9.72e-01 6.36e-01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  7.1806052e+00 1.36e-02 4.34e-01  -1.0 9.72e-01    -  8.29e-01 1.00e+00h  1\n",
      "   2  6.9669220e+00 1.16e-03 2.67e-02  -1.7 1.99e-01    -  9.22e-01 1.00e+00f  1\n",
      "   3  6.8134095e+00 3.65e-05 4.04e-04  -2.5 4.37e-02    -  1.00e+00 1.00e+00f  1\n",
      "   4  6.8087307e+00 6.61e-08 7.24e-07  -3.8 2.47e-03    -  1.00e+00 1.00e+00h  1\n",
      "   5  6.8087222e+00 2.96e-11 1.15e-10  -5.7 4.50e-05    -  1.00e+00 1.00e+00h  1\n",
      "   6  6.8087222e+00 3.69e-15 1.20e-14  -8.6 4.83e-07    -  1.00e+00 1.00e+00h  1\n",
      "\n",
      "Number of Iterations....: 6\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   6.8087221888797949e+00    6.8087221888797949e+00\n",
      "Dual infeasibility......:   1.1990408665951691e-14    1.1990408665951691e-14\n",
      "Constraint violation....:   3.6880221099266919e-15    3.6880221099266919e-15\n",
      "Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   2.5066082024408310e-09    2.5066082024408310e-09\n",
      "Overall NLP error.......:   2.5066082024408310e-09    2.5066082024408310e-09\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 7\n",
      "Number of objective gradient evaluations             = 7\n",
      "Number of equality constraint evaluations            = 7\n",
      "Number of inequality constraint evaluations          = 7\n",
      "Number of equality constraint Jacobian evaluations   = 7\n",
      "Number of inequality constraint Jacobian evaluations = 7\n",
      "Number of Lagrangian Hessian evaluations             = 6\n",
      "Total seconds in IPOPT                               = 0.014\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "       nlp_f  |  24.00us (  3.43us)  17.89us (  2.56us)         7\n",
      "       nlp_g  | 189.00us ( 27.00us) 183.33us ( 26.19us)         7\n",
      "  nlp_grad_f  |  23.00us (  2.88us)  23.16us (  2.89us)         8\n",
      "  nlp_hess_l  | 659.00us (109.83us) 660.28us (110.05us)         6\n",
      "   nlp_jac_g  | 296.00us ( 37.00us) 295.60us ( 36.95us)         8\n",
      "       total  |   6.98ms (  6.98ms)  17.93ms ( 17.93ms)         1\n",
      "[[ 7.32208872e-01 -3.47620670e-03]\n",
      " [ 7.01521574e-01 -4.11470475e-02]\n",
      " [ 6.71017717e-01 -7.18474116e-02]\n",
      " [ 6.41638768e-01 -9.58805548e-02]\n",
      " [ 6.14150276e-01 -1.13515014e-01]\n",
      " [ 5.89148728e-01 -1.25021055e-01]\n",
      " [ 5.67067075e-01 -1.30686805e-01]\n",
      " [ 5.48181252e-01 -1.30818913e-01]\n",
      " [ 5.32618575e-01 -1.25732362e-01]\n",
      " [ 5.20367823e-01 -1.15734045e-01]\n",
      " [ 5.11290110e-01 -1.01104199e-01]\n",
      " [ 5.05129386e-01 -8.20786055e-02]\n",
      " [ 5.01521393e-01 -5.88328997e-02]\n",
      " [ 5.00000000e-01 -3.14687257e-02]\n",
      " [ 5.00000000e-01  2.54109910e-21]]\n",
      "[[ 0.0877422  -0.09706956  0.9719348   0.05705884]\n",
      " [ 0.08935071 -0.0948      0.97187086  0.09366928]\n",
      " [ 0.09206378 -0.09196084  0.97132235  0.12874536]\n",
      " [ 0.0958758  -0.08844453  0.97007008  0.16229625]\n",
      " [ 0.10076791 -0.08415295  0.96799726  0.19437818]\n",
      " [ 0.10671176 -0.07899403  0.96507744  0.2250857 ]\n",
      " [ 0.11367235 -0.07287975  0.96136231  0.25454313]\n",
      " [ 0.12161008 -0.06572501  0.95696964  0.28289649]\n",
      " [ 0.13048215 -0.05744686  0.95207174  0.31030555]\n",
      " [ 0.14024337 -0.0479636   0.94688517  0.33693648]\n",
      " [ 0.15084631 -0.03719379  0.94166255  0.36295487]\n",
      " [ 0.16224078 -0.02505474  0.9366868   0.38851938]\n",
      " [ 0.17437263 -0.01146062  0.93226825  0.41377585]\n",
      " [ 0.18718165  0.00367985  0.92874467  0.43885191]\n",
      " [ 0.20059865  0.02046608  0.92648424  0.46385191]\n",
      " [ 0.21454138  0.03900886  0.92589163  0.48885191]]\n"
     ]
    }
   ],
   "source": [
    "# casadi mpc with exact penalty\n",
    "test_q = np.array([ 0.,  6.,  1.,  0., 0., 0., 1., 2.])\n",
    "test_p = np.array([ -2.,  0.,  0.,  0., 100., 100.,  -1,  0.])\n",
    "\n",
    "control = casadi_control.CasadiControl(track_coord)\n",
    "\n",
    "x0 = (sample_xinit(1)).numpy()\n",
    "print(x0[0])\n",
    "dc = 2 #number constraints\n",
    "dx = n_state #number states\n",
    "du = n_ctrl #number control inputs\n",
    "horizon = mpc_T\n",
    "sol = control.mpc_casadi(test_q,test_p,x0,horizon,dc,dx,du,track_width)\n",
    "N = horizon\n",
    "u = sol[-du*N:]\n",
    "x = sol[:-du*N]\n",
    "u_r = u.reshape(N,du)\n",
    "x_r = x.reshape(N+1,dx-dc)\n",
    "print(u_r)\n",
    "print(x_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.14.11, running with linear solver MUMPS 5.4.1.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:      304\n",
      "Number of nonzeros in inequality constraint Jacobian.:       46\n",
      "Number of nonzeros in Lagrangian Hessian.............:      225\n",
      "\n",
      "Total number of variables............................:       94\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:       64\n",
      "Total number of inequality constraints...............:       46\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:       46\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  0.0000000e+00 9.72e-01 6.36e-01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  7.1727665e+00 1.36e-02 4.34e-01  -1.0 9.72e-01    -  8.29e-01 1.00e+00h  1\n",
      "   2  6.9775922e+00 1.22e-03 7.14e-02  -1.7 1.93e-01    -  8.36e-01 1.00e+00f  1\n",
      "   3  6.8135063e+00 3.66e-05 5.09e-04  -2.5 4.88e-02    -  1.00e+00 1.00e+00f  1\n",
      "   4  6.8087367e+00 1.11e-07 1.36e-06  -3.8 3.23e-03    -  1.00e+00 1.00e+00h  1\n",
      "   5  6.8087222e+00 3.21e-11 1.50e-10  -5.7 4.76e-05    -  1.00e+00 1.00e+00h  1\n",
      "   6  6.8087222e+00 3.72e-15 1.40e-14  -8.6 4.71e-07    -  1.00e+00 1.00e+00h  1\n",
      "\n",
      "Number of Iterations....: 6\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   6.8087221888798215e+00    6.8087221888798215e+00\n",
      "Dual infeasibility......:   1.3988810110276972e-14    1.3988810110276972e-14\n",
      "Constraint violation....:   3.7218492177082396e-15    3.7218492177082396e-15\n",
      "Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   2.5065899544724404e-09    2.5065899544724404e-09\n",
      "Overall NLP error.......:   2.5065899544724404e-09    2.5065899544724404e-09\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 7\n",
      "Number of objective gradient evaluations             = 7\n",
      "Number of equality constraint evaluations            = 7\n",
      "Number of inequality constraint evaluations          = 7\n",
      "Number of equality constraint Jacobian evaluations   = 7\n",
      "Number of inequality constraint Jacobian evaluations = 7\n",
      "Number of Lagrangian Hessian evaluations             = 6\n",
      "Total seconds in IPOPT                               = 0.005\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "      solver  :   t_proc      (avg)   t_wall      (avg)    n_eval\n",
      "       nlp_f  |  12.00us (  1.71us)  10.11us (  1.44us)         7\n",
      "       nlp_g  | 188.00us ( 26.86us) 184.79us ( 26.40us)         7\n",
      "  nlp_grad_f  |  16.00us (  2.00us)  15.82us (  1.98us)         8\n",
      "  nlp_hess_l  | 611.00us (101.83us) 612.88us (102.15us)         6\n",
      "   nlp_jac_g  | 314.00us ( 39.25us) 294.15us ( 36.77us)         8\n",
      "       total  |   5.46ms (  5.46ms)   5.40ms (  5.40ms)         1\n",
      "[[ 7.32208872e-01 -3.47620661e-03]\n",
      " [ 7.01521574e-01 -4.11470475e-02]\n",
      " [ 6.71017717e-01 -7.18474116e-02]\n",
      " [ 6.41638768e-01 -9.58805548e-02]\n",
      " [ 6.14150276e-01 -1.13515014e-01]\n",
      " [ 5.89148728e-01 -1.25021055e-01]\n",
      " [ 5.67067075e-01 -1.30686805e-01]\n",
      " [ 5.48181252e-01 -1.30818913e-01]\n",
      " [ 5.32618575e-01 -1.25732362e-01]\n",
      " [ 5.20367823e-01 -1.15734045e-01]\n",
      " [ 5.11290110e-01 -1.01104199e-01]\n",
      " [ 5.05129386e-01 -8.20786055e-02]\n",
      " [ 5.01521393e-01 -5.88328997e-02]\n",
      " [ 5.00000000e-01 -3.14687257e-02]\n",
      " [ 5.00000000e-01 -4.92292688e-12]]\n",
      "[[ 0.0877422  -0.09706956  0.9719348   0.05705884]\n",
      " [ 0.08935071 -0.0948      0.97187086  0.09366928]\n",
      " [ 0.09206378 -0.09196084  0.97132235  0.12874536]\n",
      " [ 0.0958758  -0.08844453  0.97007008  0.16229625]\n",
      " [ 0.10076791 -0.08415295  0.96799726  0.19437818]\n",
      " [ 0.10671176 -0.07899403  0.96507744  0.2250857 ]\n",
      " [ 0.11367235 -0.07287975  0.96136231  0.25454313]\n",
      " [ 0.12161008 -0.06572501  0.95696964  0.28289649]\n",
      " [ 0.13048215 -0.05744686  0.95207174  0.31030555]\n",
      " [ 0.14024337 -0.0479636   0.94688517  0.33693648]\n",
      " [ 0.15084631 -0.03719379  0.94166255  0.36295487]\n",
      " [ 0.16224078 -0.02505474  0.9366868   0.38851938]\n",
      " [ 0.17437263 -0.01146062  0.93226825  0.41377585]\n",
      " [ 0.18718165  0.00367985  0.92874467  0.43885191]\n",
      " [ 0.20059865  0.02046608  0.92648424  0.46385191]\n",
      " [ 0.21454138  0.03900886  0.92589163  0.48885191]]\n"
     ]
    }
   ],
   "source": [
    "#casadi mpc with state constraints - NOTE: cost parameter vector has now different dimensions\n",
    "test_q = np.array([ 0.,  6.,  1.,  0., 1., 2.])\n",
    "test_p = np.array([ -2.,  0.,  0.,  0.,  -1,  0.])\n",
    "\n",
    "sol = control.mpc_casadi_with_constraints(test_q,test_p,x0,horizon,dc,dx,du,track_width)\n",
    "N = horizon\n",
    "u = sol[-du*N:]\n",
    "x = sol[:-du*N]\n",
    "u_r = u.reshape(N,du)\n",
    "x_r = x.reshape(N+1,dx-dc)\n",
    "print(u_r)\n",
    "print(x_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each mpc returns a prediction of the states and the inputs over the horizon for all batches and all dimensions,\n",
    "# they are stored in the following order pred_x = [horizon,batch, dimension].\n",
    "# To penalize a control behaviour that does not enforce enough progress within a horizon we can try to chose \n",
    "# our loss as -pred_x[mpc_T-1,:,0]\n",
    "\n",
    "def get_loss_progress(x_init, dx, _Q, _p, mpc_T=mpc_T):    \n",
    "        \n",
    "        pred_x, pred_u, pred_objs = mpc.MPC(\n",
    "            dx.n_state, dx.n_ctrl, mpc_T,\n",
    "            u_lower=u_lower, u_upper=u_upper, u_init=u_init,\n",
    "            lqr_iter=lqr_iter,\n",
    "            verbose=0,\n",
    "            exit_unconverged=False,\n",
    "            detach_unconverged=True,\n",
    "            linesearch_decay=dx.linesearch_decay,\n",
    "            max_linesearch_iter=dx.max_linesearch_iter,\n",
    "            grad_method=grad_method,\n",
    "            eps=0.5,\n",
    "            n_batch=n_batch,\n",
    "        )(x_init, QuadCost(_Q, _p), dx)\n",
    "        \n",
    "        #I added the second term to account the initial state (to kind of normalize the progress)\n",
    "        progress_loss = torch.mean(-pred_x[mpc_T-1,:,0] + pred_x[0,:,0])\n",
    "        \n",
    "        #penalty_loss = pred_x[]\n",
    "            \n",
    "        return progress_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = []\n",
    "learn_q_logit_state = torch.ones(n_state-2, requires_grad=True).to(device)\n",
    "learn_q_logit_input = torch.ones(n_ctrl, requires_grad=True).to(device)\n",
    "learn_p_state = torch.zeros(n_state-2, requires_grad=True).to(device)\n",
    "learn_p_input = torch.zeros(n_ctrl, requires_grad=True).to(device)\n",
    "params1 += [learn_q_logit_state, learn_q_logit_input, learn_p_state, learn_p_input]\n",
    "env_params = true_dx.params\n",
    "q_penalty = .01*torch.ones(2).to(device)\n",
    "p_penalty = 10*torch.ones(2).to(device)\n",
    "track_coord = track_coord.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn_q_logit = torch.ones_like(true_q, requires_grad=True).to(device)\n",
    "#learn_p = torch.zeros_like(true_p, requires_grad=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = [{\n",
    "            'params': params1,\n",
    "            'lr': 2e-3,\n",
    "            'alpha': 0.99,\n",
    "            }]\n",
    "dx = true_dx.__class__(track_coord,env_params)\n",
    "\n",
    "opt = optim.RMSprop(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alan/Desktop/envs/pao_env/lib/python3.8/site-packages/torch/autograd/__init__.py:411: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/alan/Desktop/envs/pao_env/lib/python3.8/site-packages/torch/_tensor.py:770: UserWarning: torch.lu is deprecated in favor of torch.linalg.lu_factor / torch.linalg.lu_factor_ex and will be removed in a future PyTorch release.\n",
      "LU, pivots = torch.lu(A, compute_pivots)\n",
      "should be replaced with\n",
      "LU, pivots = torch.linalg.lu_factor(A, compute_pivots)\n",
      "and\n",
      "LU, pivots, info = torch.lu(A, compute_pivots, get_infos=True)\n",
      "should be replaced with\n",
      "LU, pivots, info = torch.linalg.lu_factor_ex(A, compute_pivots) (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1992.)\n",
      "  LU, pivots, infos = torch._lu_with_info(\n",
      "/home/alan/Desktop/Research/Code/race_application/mpc/pnqp.py:19: UserWarning: torch.lu_solve is deprecated in favor of torch.linalg.lu_solveand will be removed in a future PyTorch release.\n",
      "Note that torch.linalg.lu_solve has its arguments reversed.\n",
      "X = torch.lu_solve(B, LU, pivots)\n",
      "should be replaced with\n",
      "X = torch.linalg.lu_solve(LU, pivots, B) (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2149.)\n",
      "  x_init = -q.unsqueeze(2).lu_solve(*H_lu).squeeze(2) # Clamped in the x assignment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0  Progression with MPC_T= 15 :  0.0396\n",
      "Batch: 1  Progression with MPC_T= 15 :  0.0377\n",
      "Batch: 2  Progression with MPC_T= 15 :  0.027\n",
      "Batch: 3  Progression with MPC_T= 15 :  0.0362\n",
      "Batch: 4  Progression with MPC_T= 15 :  0.0451\n",
      "Batch: 5  Progression with MPC_T= 15 :  0.0601\n",
      "Batch: 6  Progression with MPC_T= 15 :  0.0419\n",
      "Batch: 7  Progression with MPC_T= 15 :  0.0483\n",
      "Batch: 8  Progression with MPC_T= 15 :  0.0354\n",
      "Batch: 9  Progression with MPC_T= 15 :  0.052\n",
      "Batch: 10  Progression with MPC_T= 15 :  0.0587\n",
      "Batch: 11  Progression with MPC_T= 15 :  0.0617\n",
      "Batch: 12  Progression with MPC_T= 15 :  0.069\n",
      "Batch: 13  Progression with MPC_T= 15 :  0.0699\n",
      "Batch: 14  Progression with MPC_T= 15 :  0.072\n",
      "Batch: 15  Progression with MPC_T= 15 :  0.0648\n",
      "Batch: 16  Progression with MPC_T= 15 :  0.0696\n",
      "Batch: 17  Progression with MPC_T= 15 :  0.0992\n",
      "Batch: 18  Progression with MPC_T= 15 :  0.0681\n",
      "Batch: 19  Progression with MPC_T= 15 :  0.0827\n",
      "Batch: 20  Progression with MPC_T= 15 :  0.0841\n",
      "Batch: 21  Progression with MPC_T= 15 :  0.0747\n",
      "Batch: 22  Progression with MPC_T= 15 :  0.0963\n",
      "Batch: 23  Progression with MPC_T= 15 :  0.0499\n",
      "Batch: 24  Progression with MPC_T= 15 :  0.0853\n",
      "Batch: 25  Progression with MPC_T= 15 :  0.1005\n",
      "Batch: 26  Progression with MPC_T= 15 :  0.0762\n",
      "Batch: 27  Progression with MPC_T= 15 :  0.0823\n",
      "Batch: 28  Progression with MPC_T= 15 :  0.0824\n",
      "Batch: 29  Progression with MPC_T= 15 :  0.0776\n",
      "Batch: 30  Progression with MPC_T= 15 :  0.0958\n",
      "Batch: 31  Progression with MPC_T= 15 :  0.1428\n",
      "Batch: 32  Progression with MPC_T= 15 :  0.1113\n",
      "Batch: 33  Progression with MPC_T= 15 :  0.091\n",
      "Batch: 34  Progression with MPC_T= 15 :  0.0962\n",
      "Batch: 35  Progression with MPC_T= 15 :  0.1175\n",
      "Batch: 36  Progression with MPC_T= 15 :  0.0955\n",
      "Batch: 37  Progression with MPC_T= 15 :  0.0972\n",
      "Batch: 38  Progression with MPC_T= 15 :  0.0913\n",
      "Batch: 39  Progression with MPC_T= 15 :  0.1325\n",
      "Batch: 40  Progression with MPC_T= 15 :  0.1094\n",
      "Batch: 41  Progression with MPC_T= 15 :  0.1034\n",
      "Batch: 42  Progression with MPC_T= 15 :  0.139\n",
      "Batch: 43  Progression with MPC_T= 15 :  0.1379\n",
      "Batch: 44  Progression with MPC_T= 15 :  0.1106\n",
      "Batch: 45  Progression with MPC_T= 15 :  0.1444\n",
      "Batch: 46  Progression with MPC_T= 15 :  0.1114\n",
      "Batch: 47  Progression with MPC_T= 15 :  0.1223\n",
      "Batch: 48  Progression with MPC_T= 15 :  0.1083\n",
      "Batch: 49  Progression with MPC_T= 15 :  0.1535\n",
      "Batch: 50  Progression with MPC_T= 15 :  0.142\n",
      "Batch: 51  Progression with MPC_T= 15 :  0.1017\n",
      "Batch: 52  Progression with MPC_T= 15 :  0.1256\n",
      "Batch: 53  Progression with MPC_T= 15 :  0.1438\n",
      "Batch: 54  Progression with MPC_T= 15 :  0.1519\n",
      "Batch: 55  Progression with MPC_T= 15 :  0.1367\n",
      "Batch: 56  Progression with MPC_T= 15 :  0.2026\n",
      "Batch: 57  Progression with MPC_T= 15 :  0.1666\n",
      "Batch: 58  Progression with MPC_T= 15 :  0.144\n",
      "Batch: 59  Progression with MPC_T= 15 :  0.1375\n",
      "Batch: 60  Progression with MPC_T= 15 :  0.1304\n",
      "Batch: 61  Progression with MPC_T= 15 :  0.1723\n",
      "Batch: 62  Progression with MPC_T= 15 :  0.1762\n",
      "Batch: 63  Progression with MPC_T= 15 :  0.1663\n",
      "Batch: 64  Progression with MPC_T= 15 :  0.1815\n",
      "Batch: 65  Progression with MPC_T= 15 :  0.1525\n",
      "Batch: 66  Progression with MPC_T= 15 :  0.19\n",
      "Batch: 67  Progression with MPC_T= 15 :  0.1669\n",
      "Batch: 68  Progression with MPC_T= 15 :  0.1902\n",
      "Batch: 69  Progression with MPC_T= 15 :  0.1791\n",
      "Batch: 70  Progression with MPC_T= 15 :  0.1766\n",
      "Batch: 71  Progression with MPC_T= 15 :  0.1636\n",
      "Batch: 72  Progression with MPC_T= 15 :  0.1847\n",
      "Batch: 73  Progression with MPC_T= 15 :  0.1987\n",
      "Batch: 74  Progression with MPC_T= 15 :  0.2029\n",
      "Batch: 75  Progression with MPC_T= 15 :  0.2085\n",
      "Batch: 76  Progression with MPC_T= 15 :  0.2375\n",
      "Batch: 77  Progression with MPC_T= 15 :  0.212\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n",
      "Batch: 78  Progression with MPC_T= 15 :  0.2\n",
      "Batch: 79  Progression with MPC_T= 15 :  0.2241\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m x_init \u001b[38;5;241m=\u001b[39m sample_xinit(n_batch)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#im_loss = get_loss_cost(x_init, dx, Q_batch, p_batch)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m im_loss \u001b[38;5;241m=\u001b[39m \u001b[43mget_loss_progress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     17\u001b[0m im_loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mget_loss_progress\u001b[0;34m(x_init, dx, _Q, _p, mpc_T)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_loss_progress\u001b[39m(x_init, dx, _Q, _p, mpc_T\u001b[38;5;241m=\u001b[39mmpc_T):    \n\u001b[0;32m----> 8\u001b[0m         pred_x, pred_u, pred_objs \u001b[38;5;241m=\u001b[39m \u001b[43mmpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMPC\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_ctrl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmpc_T\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mu_lower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mu_lower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_upper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mu_upper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mu_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlqr_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlqr_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexit_unconverged\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdetach_unconverged\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlinesearch_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinesearch_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_linesearch_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_linesearch_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgrad_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQuadCost\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_Q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_p\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;66;03m#I added the second term to account the initial state (to kind of normalize the progress)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m         progress_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39mpred_x[mpc_T\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m pred_x[\u001b[38;5;241m0\u001b[39m,:,\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/envs/pao_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/envs/pao_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Research/Code/race_application/mpc/mpc.py:255\u001b[0m, in \u001b[0;36mMPC.forward\u001b[0;34m(self, x_init, cost, dx)\u001b[0m\n\u001b[1;32m    253\u001b[0m     F, f \u001b[38;5;241m=\u001b[39m dx\u001b[38;5;241m.\u001b[39mF, dx\u001b[38;5;241m.\u001b[39mf\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 255\u001b[0m     F, f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinearize_dynamics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach_maybe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cost, QuadCost):\n\u001b[1;32m    259\u001b[0m     C, c \u001b[38;5;241m=\u001b[39m cost\u001b[38;5;241m.\u001b[39mC, cost\u001b[38;5;241m.\u001b[39mc\n",
      "File \u001b[0;32m~/Desktop/Research/Code/race_application/mpc/mpc.py:542\u001b[0m, in \u001b[0;36mMPC.linearize_dynamics\u001b[0;34m(self, x, u, dynamics, diff)\u001b[0m\n\u001b[1;32m    540\u001b[0m Rt, St \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_state):\n\u001b[0;32m--> 542\u001b[0m     Rj, Sj \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_x\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mut\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m diff:\n\u001b[1;32m    546\u001b[0m         Rj, Sj \u001b[38;5;241m=\u001b[39m Rj\u001b[38;5;241m.\u001b[39mdata, Sj\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m~/Desktop/envs/pao_env/lib/python3.8/site-packages/torch/autograd/__init__.py:411\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    408\u001b[0m         grad_outputs_\n\u001b[1;32m    409\u001b[0m     )\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 411\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    422\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    424\u001b[0m     ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(150):\n",
    "\n",
    "    q = torch.cat((learn_q_logit_state,q_penalty,learn_q_logit_input),dim=0)\n",
    "    p = torch.cat((learn_p_state,p_penalty,learn_p_input), dim=0)\n",
    "    #print(q)\n",
    "\n",
    "    Q_batch = torch.diag(q).unsqueeze(0).unsqueeze(0).repeat(\n",
    "                mpc_T, n_batch, 1, 1\n",
    "            )\n",
    "    p_batch = p.unsqueeze(0).repeat(mpc_T, n_batch, 1)\n",
    "\n",
    "    x_init = sample_xinit(n_batch).to(device)\n",
    "    #im_loss = get_loss_cost(x_init, dx, Q_batch, p_batch)\n",
    "    im_loss = get_loss_progress(x_init, dx, Q_batch, p_batch)\n",
    "\n",
    "    opt.zero_grad()\n",
    "    im_loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    print('Batch:', i , ' Progression with MPC_T=',mpc_T ,': ', -round(im_loss.item(), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can choose the number of samples we want to test (number of initial states)\n",
    "N_test = 1\n",
    "\n",
    "# Whatever I wrote below might be wrong, we have to see if we really can change the mpc_T to Test, \n",
    "# it gives weird results sometimes.\n",
    "# Here we can choose the mpc_T in the test time, which can be much higher than in the training.\n",
    "# Ideally, we would like to have the whole lap here, I guess. But we need to fix the warnings/errors before.\n",
    "mpc_T_test = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init_test = sample_xinit(N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below you can put any initial state you want (any that make sense)\n",
    "x_init_test = torch.tensor([[1.6, 0.1, -0.8, 0.1,softplus_op(torch.Tensor([-0.1-0.5*track_width])), softplus_op(torch.Tensor([-0.1-0.5*track_width]))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_test = torch.diag(q).unsqueeze(0).unsqueeze(0).repeat(\n",
    "                mpc_T_test, N_test, 1, 1\n",
    "            )\n",
    "p_test = p.unsqueeze(0).repeat(mpc_T_test, N_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_q, true_p = true_dx.get_true_obj()\n",
    "true_q = torch.Tensor([ 0.,  3.,  1.,  0., 0., 0., 1., 2.])\n",
    "true_p = torch.Tensor([ -2.,  0.,  0.,  0., 100., 100.,  -1,  0.])\n",
    "\n",
    "true_q = true_q.to(device)\n",
    "true_p = true_p.to(device)\n",
    "\n",
    "expert_Q = torch.diag(true_q).unsqueeze(0).unsqueeze(0).repeat(\n",
    "            mpc_T_test, N_test, 1, 1\n",
    "        )\n",
    "expert_p = true_p.unsqueeze(0).repeat(mpc_T_test, N_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added here the bounds of U\n",
    "u_lower_test = torch.tensor([-2., -1.]).unsqueeze(0).unsqueeze(0).repeat(mpc_T_test, N_test, 1)\n",
    "u_upper_test = torch.tensor([2., 1.]).unsqueeze(0).unsqueeze(0).repeat(mpc_T_test, N_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] pnqp warning: Did not converge\n",
      "[WARNING] pnqp warning: Did not converge\n",
      "[WARNING] pnqp warning: Did not converge\n",
      "[WARNING] pnqp warning: Did not converge\n",
      "[WARNING] pnqp warning: Did not converge\n",
      "LQR Warning: All examples did not converge to a fixed point.\n",
      "Detaching and *not* backpropping through the bad examples.\n"
     ]
    }
   ],
   "source": [
    "x_mpc_test, u_mpc_test, objs_mpc_test = mpc.MPC(\n",
    "            n_state, n_ctrl, mpc_T_test,\n",
    "            u_lower=u_lower_test, u_upper=u_upper_test, u_init=u_init,\n",
    "            lqr_iter=lqr_iter,\n",
    "            verbose=0,\n",
    "            exit_unconverged=False,\n",
    "            detach_unconverged=True,\n",
    "            linesearch_decay=dx.linesearch_decay,\n",
    "            max_linesearch_iter=dx.max_linesearch_iter,\n",
    "            grad_method=grad_method,\n",
    "            eps=eps,\n",
    "            n_batch=N_test,\n",
    "        )(x_init_test, QuadCost(expert_Q, expert_p), dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frenet_to_cartesian(point_f, ref_path):\n",
    "    \n",
    "    def get_nearest_index(point_f, ref_path):\n",
    "        return ((point_f[0] - ref_path[2,:])**2).argmin()\n",
    "    \n",
    "    def compute_x_coord(point_f, ref_path, nearest_index):\n",
    "        return ref_path[0,nearest_index] - point_f[1]*torch.sin(ref_path[3,nearest_index])\n",
    "    \n",
    "    def compute_y_coord(point_f, ref_path, nearest_index):\n",
    "        return ref_path[1,nearest_index] + point_f[1]*torch.cos(ref_path[3,nearest_index])\n",
    "    \n",
    "    nearest_index = get_nearest_index(point_f, ref_path)\n",
    "    x = compute_x_coord(point_f, ref_path, nearest_index)\n",
    "    y = compute_y_coord(point_f, ref_path, nearest_index)\n",
    "    \n",
    "    return torch.tensor([x, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list = []\n",
    "y_list = []\n",
    "\n",
    "for i in range(mpc_T_test):\n",
    "    xy = frenet_to_cartesian(x_mpc_test[i,0,:2], track_coord)\n",
    "    x_list.append(xy[0].numpy())\n",
    "    y_list.append(xy[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.array(x_list)\n",
    "y_plot = np.array(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6193, 0.8438], grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_mpc_test.max(0)[0].max(0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_init: 0.15000000000000002\n",
      "y_init: -1.0499999999999994\n",
      "yaw_init: 0.0\n",
      "Total Arc Length: 11.568244517641709\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(10,5), dpi=120)\n",
    "gen.plotPoints(ax)\n",
    "#gen.pointAtArcLength(0)\n",
    "#gen.writePointsToYaml('../tracks/' + track_name + '.yaml', track_density)\n",
    "\n",
    "ax.scatter(x_plot, y_plot, s=4, color='red')\n",
    "\n",
    "print('x_init: ' + str(gen.xCoords[0]))\n",
    "print('y_init: ' + str(gen.yCoords[0]))\n",
    "print('yaw_init: ' + str(gen.tangentAngle[0]))\n",
    "print('Total Arc Length: ' + str(gen.arcLength[-1]/2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pao_env",
   "language": "python",
   "name": "pao_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
