{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Aug 12 09:40:18 AM: Encountered unexpected exception importing solver GLOP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.5.2237). Expected < 9.5.0.Please open a feature request on cvxpy to enable support for this version.')\n",
      "(CVXPY) Aug 12 09:40:18 AM: Encountered unexpected exception importing solver PDLP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.5.2237). Expected < 9.5.0.Please open a feature request on cvxpy to enable support for this version.')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpc.track.src import simple_track_generator, track_functions\n",
    "\n",
    "from torch.func import jacfwd, vmap\n",
    "\n",
    "import utils\n",
    "\n",
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "\n",
    "import torch.autograd.functional as F\n",
    "\n",
    "from mpc import casadi_control\n",
    "\n",
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from casadi import *\n",
    "\n",
    "class CasadiControl():\n",
    "    def __init__(self, track_coordinates, params):\n",
    "        super().__init__()\n",
    "\n",
    "        params = params.numpy()\n",
    "        \n",
    "        # states: sigma, d, phi, v (4) + sigma_0, sigma_diff (2) + d_pen (1) + v_ub (1) + ac_ub (1)\n",
    "        self.n_state = 4+2+1+1+1\n",
    "        print(self.n_state)          # here add amount of states plus amount of exact penalty terms\n",
    "        # control: a, delta\n",
    "        self.n_ctrl = 2\n",
    "\n",
    "        self.track_coordinates = track_coordinates\n",
    "\n",
    "        # everything to calculate curvature\n",
    "        self.track_sigma = self.track_coordinates[2,:]\n",
    "        self.track_curv = self.track_coordinates[4,:]\n",
    "\n",
    "        self.track_curv_shift = torch.empty(self.track_curv.size())\n",
    "        self.track_curv_shift[1:] = self.track_curv[0:-1]\n",
    "        self.track_curv_shift[0] = self.track_curv[-1]\n",
    "        self.track_curv_diff = self.track_curv - self.track_curv_shift\n",
    "\n",
    "        self.mask = torch.where(torch.absolute(self.track_curv_diff) < 0.1, False, True)\n",
    "        self.sigma_f = self.track_sigma[self.mask]\n",
    "        self.curv_f = self.track_curv_diff[self.mask]\n",
    "\n",
    "        self.params = params\n",
    "\n",
    "        self.l_r = params[0]\n",
    "        self.l_f = params[1]\n",
    "        \n",
    "        self.track_width = params[2]\n",
    "        \n",
    "        self.delta_threshold_rad = np.pi\n",
    "        self.dt = params[3]\n",
    "\n",
    "        self.smooth_curve = params[4]\n",
    "        \n",
    "        self.v_max = params[5]\n",
    "        \n",
    "        self.delta_max = params[6]\n",
    "        \n",
    "        self.a_max = params[7]\n",
    "        \n",
    "        self.mpc_T = int(params[8])\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return (tanh(x/2)+1.)/2\n",
    "\n",
    "    def curv_casadi(self, sigma):\n",
    "        \n",
    "        num_sf = self.sigma_f.size()\n",
    "        num_s = sigma.size()\n",
    "\n",
    "        sigma_f_mat = self.sigma_f.repeat(num_s[1],1)\n",
    "   \n",
    "        sigma_f_mat_np = sigma_f_mat.numpy()\n",
    "        sigma_f_np = self.sigma_f.numpy()\n",
    "        curv_f_np = self.curv_f.numpy()\n",
    "\n",
    "        sigma_shifted = reshape(sigma,num_s[1],1)- sigma_f_mat_np\n",
    "        curv_unscaled = self.sigmoid(self.smooth_curve*sigma_shifted)\n",
    "        curv = reshape((curv_unscaled@(curv_f_np.reshape(-1,1))),1,num_s[1])\n",
    "\n",
    "        return curv\n",
    "    \n",
    "    \n",
    "    def mpc_casadi(self,q,p,x0_np,dx,du):\n",
    "        mpc_T = self.mpc_T\n",
    "\n",
    "        x_sym = SX.sym('x_sym',dx,mpc_T+1)\n",
    "        u_sym = SX.sym('u_sym',du,mpc_T)\n",
    "\n",
    "        beta = np.arctan(l_r/(l_r+l_f)*np.tan(u_sym[1,0:mpc_T]))\n",
    "\n",
    "        dyn1 = horzcat(\n",
    "            (x_sym[0,0] - x0_np[0]), \n",
    "            (x_sym[0,1:mpc_T+1] - x_sym[0,0:mpc_T] - dt*(x_sym[3,0:mpc_T]*(np.cos(x_sym[2,0:mpc_T]+beta)/(1.-self.curv_casadi(x_sym[0,0:mpc_T])*x_sym[1,0:mpc_T])))))\n",
    "\n",
    "        dyn2 = horzcat(\n",
    "            (x_sym[1,0] - x0_np[1]), \n",
    "            (x_sym[1,1:mpc_T+1] - x_sym[1,0:mpc_T] - dt*(x_sym[3,0:mpc_T]*np.sin(x_sym[2,0:mpc_T]+beta))))\n",
    "\n",
    "        dyn3 = horzcat(\n",
    "            (x_sym[2,0] - x0_np[2]), \n",
    "            (x_sym[2,1:mpc_T+1] - x_sym[2,0:mpc_T] - dt*(x_sym[3,0:mpc_T]*(1/l_f)*np.sin(beta)-self.curv_casadi(x_sym[0,0:mpc_T])*x_sym[3,0:mpc_T]*(np.cos(x_sym[2,0:mpc_T]+beta)/(1-self.curv_casadi(x_sym[0,0:mpc_T])*x_sym[1,0:mpc_T])))))\n",
    "\n",
    "        dyn4 = horzcat(\n",
    "            (x_sym[3,0] - x0_np[3]), \n",
    "            (x_sym[3,1:mpc_T+1] - x_sym[3,0:mpc_T] - dt*(u_sym[0,0:mpc_T])))\n",
    "\n",
    "        feat = vertcat(x_sym[0,0:mpc_T]-x0_np[0],x_sym[1:,0:mpc_T],u_sym[:,0:mpc_T])\n",
    "\n",
    "        q_sym = SX.sym('q_sym',dx+du,mpc_T)\n",
    "        p_sym = SX.sym('q_sym',dx+du,mpc_T)\n",
    "        Q_sym = diag(q_sym)\n",
    "\n",
    "        l = sum2(sum1(q_sym*feat*feat + p_sym*feat))\n",
    "        dl = substitute(substitute(l,q_sym,q),p_sym,p)\n",
    "\n",
    "        const = vertcat(\n",
    "                transpose(dyn1),\n",
    "                transpose(dyn2),\n",
    "                transpose(dyn3),\n",
    "                transpose(dyn4),\n",
    "                transpose(u_sym[0,0:mpc_T]),\n",
    "                transpose(u_sym[1,0:mpc_T]),\n",
    "                transpose(x_sym[1,0:mpc_T+1]),\n",
    "                transpose(x_sym[3,0:mpc_T+1]))\n",
    "\n",
    "        lbg = np.r_[np.zeros(mpc_T+1),\n",
    "                    np.zeros(mpc_T+1),\n",
    "                    np.zeros(mpc_T+1),\n",
    "                    np.zeros(mpc_T+1),\n",
    "                    -self.a_max*np.ones(mpc_T),\n",
    "                    -self.delta_max*np.ones(mpc_T),\n",
    "                    -0.35*self.track_width*np.ones(mpc_T+1),\n",
    "                    -0.1*np.ones(mpc_T+1)]\n",
    "\n",
    "        ubg = np.r_[np.zeros(mpc_T+1),\n",
    "                    np.zeros(mpc_T+1),\n",
    "                    np.zeros(mpc_T+1),\n",
    "                    np.zeros(mpc_T+1),\n",
    "                    self.a_max*np.ones(mpc_T),\n",
    "                    self.delta_max*np.ones(mpc_T),\n",
    "                    0.35*self.track_width*np.ones(mpc_T+1),\n",
    "                    self.v_max*np.ones(mpc_T+1)]\n",
    "\n",
    "\n",
    "        lbx = -np.inf * np.ones(dx*(mpc_T+1)+du*mpc_T)\n",
    "        ubx = np.inf * np.ones(dx*(mpc_T+1)+du*mpc_T)\n",
    "\n",
    "        x = vertcat(reshape(x_sym[:,0:mpc_T+1],(dx*(mpc_T+1),1)),\n",
    "                    reshape(u_sym[:,0:mpc_T],(du*mpc_T,1)))\n",
    "\n",
    "        options = {\n",
    "                    'verbose': False,\n",
    "                    'ipopt.print_level': 0,\n",
    "                    'print_time': 0,\n",
    "                    'ipopt.tol': 1e-4,\n",
    "                    'ipopt.max_iter': 4000,\n",
    "                    'ipopt.hessian_approximation': 'limited-memory'\n",
    "                }\n",
    "\n",
    "        nlp = {'x':x,'f':dl, 'g':const}\n",
    "        solver = nlpsol('solver','ipopt', nlp, options)\n",
    "\n",
    "        solver_input = {}\n",
    "        solver_input['lbx'] = lbx\n",
    "        solver_input['ubx'] = ubx\n",
    "        solver_input['lbg'] = lbg\n",
    "        solver_input['ubg'] = ubg\n",
    "\n",
    "        solver_output = solver(**solver_input)\n",
    "\n",
    "        sol = solver_output['x']\n",
    "\n",
    "        sol_evalf = np.squeeze(evalf(sol))\n",
    "        u = sol_evalf[-du*mpc_T:].reshape(-1,du)\n",
    "        x = sol_evalf[:-du*mpc_T].reshape(-1,dx)\n",
    "\n",
    "        return x, u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, mpc_H, mpc_T, O, K):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        input_size = 3 + mpc_H\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, mpc_T*O)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.output_activation = nn.Tanh()\n",
    "        self.K = K\n",
    "        self.O = O\n",
    "        self.mpc_T = mpc_T\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.output_activation(x) * self.K\n",
    "        x = x.reshape(-1, self.mpc_T, self.O)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_init(BS):\n",
    "    di = 1000\n",
    "    sigma_sample = torch.randint(0, int(0.5*di), (BS,1))/di\n",
    "    d_sample = torch.randint(int(-.15*di), int(.15*di), (BS,1))/di\n",
    "    phi_sample = torch.randint(int(-0.08*di), int(0.08*di), (BS,1))/di\n",
    "    v_sample = torch.randint(0, int(.22*di), (BS,1))/di\n",
    "    x_init_sample = torch.hstack((sigma_sample, d_sample, phi_sample, v_sample))\n",
    "    return x_init_sample\n",
    "\n",
    "def get_curve_hor_from_x(x, track_coord, H_curve):\n",
    "    idx_track_batch = ((x[:,0]-track_coord[[2],:].T)**2).argmin(0)\n",
    "    idcs_track_batch = idx_track_batch[:, None] + torch.arange(H_curve)\n",
    "    curvs = track_coord[4,idcs_track_batch].float()\n",
    "    return curvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrenetKinBicycleDx(nn.Module):\n",
    "    def __init__(self, track_coordinates, params, dev):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.params = params\n",
    "\n",
    "        # states: sigma, d, phi, v (4) + sigma_0, sigma_diff (2) + d_pen (1) + v_ub (1)\n",
    "        self.n_state = 4+2+1+1\n",
    "        print('Number of states:', self.n_state)\n",
    "        \n",
    "        self.n_ctrl = 2 # control: a, delta\n",
    "\n",
    "        self.track_coordinates = track_coordinates.to(dev)\n",
    "\n",
    "        # everything to calculate curvature\n",
    "        self.track_sigma = self.track_coordinates[2,:]\n",
    "        self.track_curv = self.track_coordinates[4,:]\n",
    "\n",
    "        self.track_curv_shift = torch.empty(self.track_curv.size()).to(dev)\n",
    "        self.track_curv_shift[1:] = self.track_curv[0:-1]\n",
    "        self.track_curv_shift[0] = self.track_curv[-1]\n",
    "        self.track_curv_diff = self.track_curv - self.track_curv_shift\n",
    "\n",
    "        self.mask = torch.where(torch.absolute(self.track_curv_diff) < 0.1, False, True)\n",
    "        self.sigma_f = self.track_sigma[self.mask]\n",
    "        self.curv_f = self.track_curv_diff[self.mask]\n",
    "     \n",
    "        self.l_r = params[0]\n",
    "        self.l_f = params[1]\n",
    "        \n",
    "        self.track_width = params[2]\n",
    "        \n",
    "        self.delta_threshold_rad = np.pi\n",
    "        self.dt = params[3]\n",
    "\n",
    "        self.smooth_curve = params[4]\n",
    "        \n",
    "        self.v_max = params[5]\n",
    "        \n",
    "        self.delta_max = params[6]\n",
    "                \n",
    "        \n",
    "        \n",
    "    def curv(self, sigma):\n",
    "\n",
    "        num_sf = self.sigma_f.size()\n",
    "        num_s = sigma.size()\n",
    "\n",
    "        sigma_f_mat = self.sigma_f.repeat(num_s[0],1)\n",
    "\n",
    "        sigma_shifted = sigma.reshape(-1,1) - sigma_f_mat\n",
    "        curv_unscaled = torch.sigmoid(self.smooth_curve*sigma_shifted)\n",
    "        curv = (curv_unscaled@(self.curv_f.reshape(-1,1))).type(torch.float)\n",
    "\n",
    "        return curv.reshape(-1)\n",
    "    \n",
    "    \n",
    "    def penalty_d(self, d, factor=1000.):  \n",
    "        overshoot_pos = (d - 0.34*self.track_width).clamp(min=0)\n",
    "        overshoot_neg = (-d - 0.34*self.track_width).clamp(min=0)\n",
    "        penalty_pos = torch.exp(overshoot_pos) - 1\n",
    "        penalty_neg = torch.exp(overshoot_neg) - 1 \n",
    "        return factor*(penalty_pos + penalty_neg)\n",
    "    \n",
    "    def penalty_v(self, v, factor=1000.):          \n",
    "        overshoot_pos = (v - self.v_max).clamp(min=0)\n",
    "        overshoot_neg = (-v + 0.001).clamp(min=0)\n",
    "        penalty_pos = torch.exp(overshoot_pos) - 1\n",
    "        penalty_neg = torch.exp(overshoot_neg) - 1 \n",
    "        return factor*(penalty_pos + penalty_neg)\n",
    "    \n",
    "    def penalty_delta(self, delta, factor=1000.):          \n",
    "        overshoot_pos = (delta - self.delta_max).clamp(min=0)\n",
    "        overshoot_neg = (-delta - self.delta_max).clamp(min=0)\n",
    "        penalty_pos = torch.exp(overshoot_pos) - 1\n",
    "        penalty_neg = torch.exp(overshoot_neg) - 1 \n",
    "        return factor*(penalty_pos + penalty_neg)\n",
    "    \n",
    "    def forward(self, state, u):\n",
    "        squeeze = state.ndimension() == 1\n",
    "        if squeeze:\n",
    "            state = state.unsqueeze(0)\n",
    "            u = u.unsqueeze(0)\n",
    "        if state.is_cuda and not self.params.is_cuda:\n",
    "            self.params = self.params.cuda()\n",
    "\n",
    "\n",
    "        a, delta = torch.unbind(u, dim=1)\n",
    "\n",
    "        #sigma, d, phi, v, sigma_0, sigma_diff, d_pen, v_ub = torch.unbind(state, dim=1)\n",
    "        \n",
    "        sigma, d, phi, v, sigma_0, sigma_diff = torch.unbind(state, dim=1)\n",
    "        beta = torch.atan(self.l_r/(self.l_r+self.l_f)*torch.tan(delta))       \n",
    "        k = self.curv(sigma)\n",
    "\n",
    "        dsigma = v*(torch.cos(phi+beta)/(1.-k*d))\n",
    "        dd = v*torch.sin(phi+beta)\n",
    "        dphi = v/self.l_f*torch.sin(beta)-k*v*(torch.cos(phi+beta)/(1-k*d))       \n",
    "        \n",
    "        dv = a      \n",
    "\n",
    "        sigma = sigma + self.dt * dsigma\n",
    "        d = d + self.dt * dd\n",
    "        phi = phi + self.dt * dphi\n",
    "        v = v + self.dt * dv \n",
    "        \n",
    "        sigma_diff = sigma - sigma_0 \n",
    "                \n",
    "        #d_pen = self.penalty_d(d)        \n",
    "        #v_ub = self.penalty_v(v)\n",
    "\n",
    "        #state = torch.stack((sigma, d, phi, v, sigma_0, sigma_diff, d_pen, v_ub), 1)\n",
    "        \n",
    "        state = torch.stack((sigma, d, phi, v, sigma_0, sigma_diff), 1)\n",
    "\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_casadi(q_np,p_np,x0_np,dx,du):\n",
    "    \n",
    "    x_curr_opt, u_curr_opt = control.mpc_casadi(q_np,p_np,x0_np,dx,du)\n",
    "\n",
    "    sigzero_curr_opt = np.expand_dims(x_curr_opt[[0],0].repeat(mpc_T+1), 1)\n",
    "    sigsiff_curr_opt = x_curr_opt[:,[0]]-x_curr_opt[0,0]\n",
    "\n",
    "    x_curr_opt_plus = np.concatenate((\n",
    "        x_curr_opt,sigzero_curr_opt,sigsiff_curr_opt), axis = 1)\n",
    "\n",
    "    x_star = x_curr_opt_plus[1:]\n",
    "    u_star = u_curr_opt\n",
    "    \n",
    "    return x_star, u_star\n",
    "\n",
    "\n",
    "def formulate_QP(x0_cp, x_star, u_star, true_dx):\n",
    "\n",
    "    J_x = vmap(jacfwd(true_dx.forward, 0))(torch.tensor(x_star), torch.tensor(u_star)).squeeze()\n",
    "    J_u = vmap(jacfwd(true_dx.forward, 1))(torch.tensor(x_star), torch.tensor(u_star)).squeeze()\n",
    "\n",
    "    x_cp = cp.Variable((mpc_T, dx + 2))\n",
    "    u_cp = cp.Variable((mpc_T, du))\n",
    "\n",
    "    Q_sigma_diff_sqrt = cp.Parameter((mpc_T, mpc_T))\n",
    "    Q_d_sqrt = cp.Parameter((mpc_T, mpc_T))\n",
    "\n",
    "    p_sigma_diff = cp.Parameter((mpc_T))\n",
    "    p_d = cp.Parameter((mpc_T))\n",
    "\n",
    "    objective = cp.Minimize(\n",
    "        p_sigma_diff@x_cp[:,5] \\\n",
    "        + p_d@x_cp[:,1] \\\n",
    "        + cp.sum_squares(Q_sigma_diff_sqrt @ x_cp[:,5])\n",
    "        + cp.sum_squares(Q_d_sqrt @ x_cp[:,1])\n",
    "    )\n",
    "\n",
    "    constraints = []\n",
    "\n",
    "    constraints += [x_cp[0,:4] == x0_cp]\n",
    "    constraints += [x_cp[:, 4] == x0_cp[0]]\n",
    "    constraints += [x_cp[0, 5] == 0]\n",
    "\n",
    "    constraints += [u_cp[:,1] >= -delta_max, u_cp[:,1] <= delta_max]\n",
    "    constraints += [u_cp[:,0] >= -a_max, u_cp[:,0] <= a_max]\n",
    "\n",
    "    constraints += [x_cp[:,3] >= 0, x_cp[:,3] <= v_max]\n",
    "    constraints += [x_cp[:,1] >= -track_width*0.35, x_cp[:,1] <= track_width*0.35]\n",
    "    \n",
    "    constraints += [x_cp >= -999., x_cp <= 999.]\n",
    "\n",
    "    for tt in range(mpc_T-1):\n",
    "        Jdx = (x_cp - x_star)[tt]@J_x[tt].T\n",
    "        Jdu = (u_cp - u_star)[tt]@J_u[tt].T\n",
    "        constraints += [x_cp[tt+1] == x_star[tt+1] + Jdx + Jdu]\n",
    "\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    assert problem.is_dpp() #the problem should be DPP for us to backpropagate (that is why Q_sqrt)\n",
    "\n",
    "    cvxpylayer = CvxpyLayer(\n",
    "        problem, \n",
    "        parameters=[Q_sigma_diff_sqrt, Q_d_sqrt, p_sigma_diff, p_d], \n",
    "        variables=[x_cp, u_cp])\n",
    "    \n",
    "    return cvxpylayer\n",
    "\n",
    "\n",
    "def q_and_p(mpc_T, q_p_pred):\n",
    "    # Cost order: \n",
    "    # sigma_diff, d, phi, v, a, delta\n",
    "    q = torch.zeros((6,mpc_T))\n",
    "    p = torch.zeros((6,mpc_T))\n",
    "\n",
    "    q[0,:] = q_p_pred[0,:,0].clamp(0.1)\n",
    "    q[1,:] = 5 + q_p_pred[0,:,1].clamp(0)\n",
    "    q[2,:] = 5\n",
    "\n",
    "    p[0,:] = -10 + q_p_pred[0,:,2]\n",
    "    p[1,:] = q_p_pred[0,:,3]\n",
    "    \n",
    "    return q, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_curve = 100.\n",
    "\n",
    "dt = 0.04\n",
    "\n",
    "mpc_T = 30\n",
    "mpc_H = 60\n",
    "n_batch = 32\n",
    "\n",
    "l_r = 0.2\n",
    "l_f = 0.2\n",
    "\n",
    "v_max = 2.5\n",
    "\n",
    "delta_max = 0.6\n",
    "\n",
    "a_max = 2.\n",
    "\n",
    "track_density = 300\n",
    "track_width = 0.5\n",
    "t_track = 0.3\n",
    "init_track = [0,0,0]\n",
    "\n",
    "max_p = 100 \n",
    "\n",
    "BS = 1\n",
    "\n",
    "params = torch.tensor([l_r, l_f, track_width, dt, k_curve, v_max, delta_max, a_max, mpc_T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = simple_track_generator.trackGenerator(track_density,track_width)\n",
    "track_name = 'DEMO_TRACK'\n",
    "\n",
    "track_function = {\n",
    "    'DEMO_TRACK'    : track_functions.demo_track,\n",
    "    'HARD_TRACK'    : track_functions.hard_track,\n",
    "    'LONG_TRACK'    : track_functions.long_track,\n",
    "    'LUCERNE_TRACK' : track_functions.lucerne_track,\n",
    "    'BERN_TRACK'    : track_functions.bern_track,\n",
    "    'INFINITY_TRACK': track_functions.infinity_track,\n",
    "    'SNAIL_TRACK'   : track_functions.snail_track\n",
    "}.get(track_name, track_functions.demo_track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_function(gen, t_track, init_track)\n",
    "gen.populatePointsAndArcLength()\n",
    "gen.centerTrack()\n",
    "track_coord = torch.from_numpy(np.vstack(\n",
    "    [gen.xCoords, \n",
    "     gen.yCoords, \n",
    "     gen.arcLength, \n",
    "     gen.tangentAngle, \n",
    "     gen.curvature]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states: 8\n"
     ]
    }
   ],
   "source": [
    "true_dx = FrenetKinBicycleDx(track_coord, params, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = torch.tensor([0.0, 0.1, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0])\n",
    "u0 = torch.tensor([0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx=4\n",
    "du=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "control = CasadiControl(track_coord, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN(mpc_H, mpc_T, 4, max_p)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4440,  0.0450, -0.0450,  0.0020]])\n"
     ]
    }
   ],
   "source": [
    "x0 = sample_init(BS)\n",
    "print(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_approx = 20\n",
    "\n",
    "x_ap = torch.zeros((BS,T_approx,dx))\n",
    "u_ap = torch.zeros((BS,T_approx,du))\n",
    "\n",
    "for t in range(T_approx):\n",
    "\n",
    "    curv = get_curve_hor_from_x(x0, track_coord, mpc_H)\n",
    "    inp = torch.hstack((x0[:,1:], curv))\n",
    "    q_p_pred = model(inp)\n",
    "    q, p = q_and_p(mpc_T, q_p_pred)\n",
    "\n",
    "    x0_np = x0.detach().numpy().squeeze()\n",
    "    q_np = q.detach().numpy()\n",
    "    p_np = p.detach().numpy()\n",
    "    x_star, u_star = solve_casadi(q_np,p_np,x0_np,dx,du)\n",
    "\n",
    "    cvxpylayer = formulate_QP(x0_np, x_star, u_star, true_dx)\n",
    "\n",
    "    x_approx, u_approx = cvxpylayer(\n",
    "        q[0,:].sqrt().diag(), \n",
    "        q[1,:].sqrt().diag(), \n",
    "        p[0,:], \n",
    "        p[1,:])\n",
    "\n",
    "    x0 = x_approx[1,:4].unsqueeze(0)\n",
    "    \n",
    "    x_ap[:,t] = x0\n",
    "    u_ap[:,t] = u_approx[1].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4441,  0.0461, -0.0396,  0.0820],\n",
       "         [ 0.4474,  0.0481, -0.0286,  0.1619],\n",
       "         [ 0.4542,  0.0514, -0.0115,  0.2420],\n",
       "         [ 0.4646,  0.0561,  0.0127,  0.3219],\n",
       "         [ 0.4789,  0.0630,  0.0460,  0.4019],\n",
       "         [ 0.4976,  0.0729,  0.0914,  0.4819],\n",
       "         [ 0.5214,  0.0870,  0.1510,  0.5619],\n",
       "         [ 0.5459,  0.0938,  0.1663,  0.6419],\n",
       "         [ 0.5713,  0.0897,  0.1247,  0.7219],\n",
       "         [ 0.6055,  0.1084,  0.1977,  0.8016],\n",
       "         [ 0.6372,  0.1043,  0.1459,  0.8816],\n",
       "         [ 0.6721,  0.0982,  0.0891,  0.9616],\n",
       "         [ 0.7096,  0.0892,  0.0269,  1.0416],\n",
       "         [ 0.7495,  0.0769, -0.0405,  1.1216],\n",
       "         [ 0.8084,  0.0965,  0.0734,  1.2016],\n",
       "         [ 0.8587,  0.0950,  0.0500,  1.4189],\n",
       "         [ 0.9345,  0.1398,  0.2637,  1.4989],\n",
       "         [ 0.9941,  0.1355,  0.1702,  1.5789],\n",
       "         [ 1.0182,  0.1251,  0.3892,  1.6589],\n",
       "         [ 1.1163,  0.1341,  0.0554,  1.7389]]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alan/Desktop/envs/pao_env/lib/python3.8/site-packages/torch/autograd/__init__.py:266: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't apply Jacobian with a quadratic objective.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mx_ap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/envs/pao_env/lib/python3.8/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/envs/pao_env/lib/python3.8/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/envs/pao_env/lib/python3.8/site-packages/torch/autograd/function.py:289\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    288\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/envs/pao_env/lib/python3.8/site-packages/cvxpylayers/torch/cvxpylayer.py:347\u001b[0m, in \u001b[0;36m_CvxpyLayerFn.<locals>._CvxpyLayerFnFn.backward\u001b[0;34m(ctx, *dvars)\u001b[0m\n\u001b[1;32m    345\u001b[0m grad \u001b[38;5;241m=\u001b[39m [[] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(param_ids))]\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ctx\u001b[38;5;241m.\u001b[39mbatch_size):\n\u001b[0;32m--> 347\u001b[0m     del_param_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_param_jac\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdcs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mdAs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdbs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j, pid \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(param_ids):\n\u001b[1;32m    350\u001b[0m         grad[j] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [to_torch(del_param_dict[pid],\n\u001b[1;32m    351\u001b[0m                              ctx\u001b[38;5;241m.\u001b[39mdtype, ctx\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)]\n",
      "File \u001b[0;32m~/Desktop/envs/pao_env/lib/python3.8/site-packages/cvxpy/reductions/dcp2cone/cone_matrix_stuffing.py:208\u001b[0m, in \u001b[0;36mParamConeProg.apply_param_jac\u001b[0;34m(self, delc, delA, delb, active_params)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m\"\"\"Multiplies by Jacobian of parameter mapping.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03mAssumes delA is sparse.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    A dictionary param.id -> dparam\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mP \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt apply Jacobian with a quadratic objective.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m active_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     active_params \u001b[38;5;241m=\u001b[39m {p\u001b[38;5;241m.\u001b[39mid \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters}\n",
      "\u001b[0;31mValueError\u001b[0m: Can't apply Jacobian with a quadratic objective."
     ]
    }
   ],
   "source": [
    "x_ap.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "cart_3 = np.zeros((120, 3))\n",
    "\n",
    "for i in range(120):\n",
    "    cart_3[i,:2] = utils.frenet_to_cartesian(torch.tensor(x[i]), track_coord).numpy()\n",
    "    cart_3[i,2] = x[i,3]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,4), dpi=150)\n",
    "gen.plotPoints(ax)\n",
    "\n",
    "\n",
    "custom_cmap = plt.get_cmap('cubehelix').reversed()\n",
    "sct = ax.scatter(cart_3[:,0], cart_3[:,1], \n",
    "                 c=cart_3[:,2], cmap=custom_cmap, s=4)\n",
    "\n",
    "cbar = plt.colorbar(sct)\n",
    "cbar.set_label('Velocity') \n",
    "#sct = ax.scatter(cart[:,0].numpy(), cart[:,1].numpy(), s=4, color='red')\n",
    "#sct = ax.scatter(cart_2[:,0].numpy(), cart_2[:,1].numpy(), s=4, color='green')\n",
    "#sct = ax.scatter(cart_3[:,0].detach().numpy(), cart_3[:,1].detach().numpy(), s=4, color='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "cart_3 = torch.zeros((n_sim, 3))\n",
    "\n",
    "x = x0_1\n",
    "for i in range(n_sim):\n",
    "    x_aux = true_dx.forward(x, a_delta_learned[-190].detach()[i])\n",
    "    x = x_aux.clone().squeeze()\n",
    "    cart_3[i,:2] = utils.frenet_to_cartesian(x, track_coord)\n",
    "    cart_3[i,2] = x[3]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,4), dpi=150)\n",
    "gen.plotPoints(ax)\n",
    "\n",
    "custom_cmap = plt.get_cmap('cubehelix').reversed()\n",
    "sct = ax.scatter(cart_3[:,0].detach().numpy(), cart_3[:,1].detach().numpy(), \n",
    "                 c=cart_3[:,2], cmap=custom_cmap, s=4)\n",
    "cbar = plt.colorbar(sct)\n",
    "cbar.set_label('Velocity') \n",
    "#sct = ax.scatter(cart[:,0].numpy(), cart[:,1].numpy(), s=4, color='red')\n",
    "#sct = ax.scatter(cart_2[:,0].numpy(), cart_2[:,1].numpy(), s=4, color='green')\n",
    "#sct = ax.scatter(cart_3[:,0].detach().numpy(), cart_3[:,1].detach().numpy(), s=4, color='blue')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = cp.Variable((BS, mpc_T))\n",
    "d = cp.Variable((BS, mpc_T))\n",
    "phi = cp.Variable((BS, mpc_T))\n",
    "v = cp.Variable((BS, mpc_T))\n",
    "sigma_0 = cp.Variable((BS, mpc_T))\n",
    "sigma_diff = cp.Variable((BS, mpc_T))\n",
    "d_pen = cp.Variable((BS, mpc_T))\n",
    "v_ub = cp.Variable((BS, mpc_T))\n",
    "a = cp.Variable((BS, mpc_T))\n",
    "delta = cp.Variable((BS, mpc_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_d = cp.Parameter((BS, mpc_T))\n",
    "Q_v = cp.Parameter((BS, mpc_T))\n",
    "p_v = torch.ones((BS, mpc_T))\n",
    "Q_d = torch.ones((BS, mpc_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = cp.Minimize(\n",
    "    cp.sum(\n",
    "        cp.sum(Q_d @ cp.square(d).T, 1) +\n",
    "        cp.sum(p_d @ d.T, 1) +\n",
    "        cp.sum(Q_v @ cp.square(v).T, 1) +\n",
    "        cp.sum(p_v @ v.T, 1)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[0][:4,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = []\n",
    "\n",
    "constraints += [delta >= -delta_max, delta <= delta_max]\n",
    "\n",
    "constraints += [v >= 0, v <= v_max]\n",
    "constraints += [d >= -track_width*0.4, d <= track_width*0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(mpc_T-1):\n",
    "    state_t = cp.hstack([sigma[t], d[t], phi[t], v[t], sigma_0[t], sigma_diff[t], d_pen[t], v_ub[t]])\n",
    "    state_t1 = cp.hstack([sigma[t+1], d[t+1], phi[t+1], v[t+1], sigma_0[t+1], sigma_diff[t+1], d_pen[t+1], v_ub[t+1]])\n",
    "    control_t = cp.hstack([a[t], delta[t]])\n",
    "    constraints += [state_t1 == A[t] @ state_t + B[t] @ control_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_delta_learned = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in range(2,n_sim+1):\n",
    "    \n",
    "    for it in range(400):\n",
    "\n",
    "        loss = torch.zeros((s,))\n",
    "        x = x0_1\n",
    "        for i in range(s):\n",
    "            x_aux = true_dx.forward(x, a_delta[i])\n",
    "            x = x_aux.clone().squeeze()\n",
    "            loss[i] = true_dx.penalty_d(x[1]) \\\n",
    "            + true_dx.penalty_v(x[3]) \\\n",
    "            + true_dx.penalty_a(a_delta[i,0]) \\\n",
    "            + true_dx.penalty_delta(a_delta[i,1])\n",
    "            #cart_3[i] = x[[0,1,2]]\n",
    "\n",
    "        loss_total = loss.sum() - x[0]\n",
    "        opt.zero_grad()\n",
    "        loss_total.backward()\n",
    "        opt.step()\n",
    "\n",
    "        if it%50==0:\n",
    "            with torch.no_grad():\n",
    "                print(s, x[0].item(), x[1].item(), x[3].item())\n",
    "                a_delta_learned.append(a_delta.detach().clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "cart_3 = torch.zeros((n_sim, 3))\n",
    "\n",
    "x = x0_1\n",
    "for i in range(n_sim):\n",
    "    x_aux = true_dx.forward(x, a_delta_learned[-190].detach()[i])\n",
    "    x = x_aux.clone().squeeze()\n",
    "    cart_3[i,:2] = utils.frenet_to_cartesian(x, track_coord)\n",
    "    cart_3[i,2] = x[3]\n",
    "    #cart_3[i] = x[[0,1,2]]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,4), dpi=150)\n",
    "gen.plotPoints(ax)\n",
    "\n",
    "custom_cmap = plt.get_cmap('cubehelix').reversed()\n",
    "sct = ax.scatter(cart_3[:,0].detach().numpy(), cart_3[:,1].detach().numpy(), \n",
    "                 c=cart_3[:,2], cmap=custom_cmap, s=4)\n",
    "cbar = plt.colorbar(sct)\n",
    "cbar.set_label('Velocity') \n",
    "#sct = ax.scatter(cart[:,0].numpy(), cart[:,1].numpy(), s=4, color='red')\n",
    "#sct = ax.scatter(cart_2[:,0].numpy(), cart_2[:,1].numpy(), s=4, color='green')\n",
    "#sct = ax.scatter(cart_3[:,0].detach().numpy(), cart_3[:,1].detach().numpy(), s=4, color='blue')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pao_env",
   "language": "python",
   "name": "pao_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
